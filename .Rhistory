file_name_lasso_yes_interaction = paste(MODELS_FOLDER_RELATIVE_PATH,
"lasso_yes_interaction",
".Rdata", collapse = "", sep = "")
save(lasso_yes_interaction, file = file_name_lasso_yes_interaction)
rm(lasso_yes_interaction)
gc()
rm(X_mm_yes_interaction_sss)
rm(X_mm_yes_interaction_vvv)
gc()
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
# Tree -------------------------------------
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
library(tree)
# Model selection
# 0) Full tree which to be pruned ------
# default: overfit
tree_full = tree(y ~.,
data = sss[id_cb1,],
control = tree.control(nobs = length(id_cb1),
mindev = 1e-04,
minsize = 5))
# check overfitting
plot(tree_full)
# Selection of size parameter, we have two possible ways
# 1.a) Size: CV ----------
# Selection of size parameter
TREE_MAX_SIZE = 100
# if parallel shows problems use the non parallel version
tree_cv_metrics = ManualCvTreeParallel(my_id_list_cv = ID_CV_LIST,
my_metric_names = METRICS_NAMES,
my_data = sss,
my_max_size = TREE_MAX_SIZE,
my_metrics_functions = MY_USED_METRICS,
my_ncores = N_CORES,
my_weights = MY_WEIGHTS_sss,
my_mindev = 1e-04,
my_minsize = 5,
use_only_first_fold = USE_ONLY_FIRST_FOLD)
tree_best_summary = CvMetricBest(my_param_values = 2:TREE_MAX_SIZE,
my_metric_matrix = tree_cv_metrics[["metrics"]],
my_one_se_best = TRUE,
my_higher_more_complex = TRUE,
my_se_matrix = tree_cv_metrics[["se"]],
my_metric_names = METRICS_NAMES)
PlotAndSave(function()(
PlotCvMetrics(my_param_values = 2:TREE_MAX_SIZE,
my_metric_matrix = tree_cv_metrics[["metrics"]],
my_se_matrix = tree_cv_metrics[["se"]],
my_best_param_values = ExtractBestParams(tree_best_summary),
my_metric_names = METRICS_NAMES,
my_main = "Tree CV metrics",
my_xlab = "size")),
my_path_plot = paste(FIGURES_FOLDER_RELATIVE_PATH,
"tree_cv_metrics_plot.jpeg",
collapse = ""))
tree_best_size = tree_best_summary[[METRIC_CHOSEN_NAME]][["best_param_value"]]
print("tree best size")
tree_best_size
# 1.b) Size: train - test -----------
# pruning
# tree_pruned = prune.tree(tree_full,
#                          newdata = sss[-id_cb1,])
#
# tree_best_size = tree_pruned$size[which.min(tree_pruned$dev)]
#
# print("tree best size")
# tree_best_size
#
# temp_plot_function = function(){
#   plot(tree_pruned)
#   plot(tree_pruned, xlim = c(0, 40))
#
#   abline(v = tree_best_size, col = "red")
# }
#
# PlotAndSave(temp_plot_function, my_path_plot = paste(FIGURES_FOLDER_RELATIVE_PATH,
#                                                      "tree_test_deviance_plot.jpeg",
#                                                      collapse = ""))
# 2) tree : final model ---------------------
final_tree_pruned = prune.tree(tree_full,
best = tree_best_size)
plot(final_tree_pruned)
text(final_tree_pruned, cex = 0.7)
df_metrics = Add_Test_Metric(df_metrics,
"tree_pruned best",
USED.Metrics(predict(final_tree_pruned, newdata = vvv),
vvv$y,
weights = MY_WEIGHTS_vvv))
df_metrics
file_name_final_tree_pruned = paste(MODELS_FOLDER_RELATIVE_PATH,
"final_tree_pruned",
".Rdata", collapse = "", sep = "")
save(final_tree_pruned, file = file_name_final_tree_pruned)
rm(final_tree_pruned)
rm(tree_full)
gc()
# save the df_metrics as .Rdata
save(df_metrics, file = "df_metrics.Rdata")
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
# Modello Additivo ---------------------------
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
library(gam)
# step selection via GCV
# stepwise forward: AIC based on generalized df
gam0 = gam(y ~ 1, data = sss)
# gam recognizes factor predictors
my_gam_scope = gam.scope(sss[,-y_index], arg = c("df=2", "df=3", "df=4", "df=5", "df=6"))
# try parallel (linux only)
# require(doMC)
# registerDoMC(cores= N_CORES)
# step.Gam(gam0, my_gam_scope, parallel=TRUE)
gam_step = step.Gam(gam0, scope = my_gam_scope)
df_metrics = Add_Test_Metric(df_metrics,
"gam_step",
USED.Metrics(predict(gam_step, newdata = vvv),
vvv$y,
weights = MY_WEIGHTS_vvv))
df_metrics
file_name_gam_step = paste(MODELS_FOLDER_RELATIVE_PATH,
"gam_step",
".Rdata", collapse = "", sep = "")
save(gam_step, file = file_name_gam_step)
rm(gam_step)
gc()
# save the df_metrics as .Rdata
save(df_metrics, file = "df_metrics.Rdata")
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
# MARS ---------------------------------------
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
# factor predictors indexes are needed
# since in the model.matrix quantitative predictors don't change colum names
# (opposite to factors -> indicator matrix for each except one value)
# we first get the quantitative predictor indexes
# and then we do a set difference
num_index = which(colnames(X_mm_no_interaction_sss) %in% var_num_names)
factor_index = setdiff(1:NCOL(X_mm_no_interaction_sss), num_index)
library(polspline)
# step selection via GCV
# only interaction of two terms are admitted
# (computational and time constraint)
mars_step = polymars(responses = sss$y,
predictors = X_mm_no_interaction_sss,
gcv = 1,
factors = factor_index,
maxsize = 60)
print("mars min size gcv")
min_size_mars = mars_step$fitting$size[which.min(mars_step$fitting$GCV)]
min_size_mars
temp_plot_function = function(){
plot(mars_step$fitting$size, mars_step$fitting$GCV,
col = as.factor(mars_step$fitting$`0/1`),
pch = 16,
xlab = "basis number",
ylab = "GCV",
main = "MARS step GCV")
legend(c("topright"),
legend = c("crescita", "potatura"),
col = c("black","red"),
pch = 16)
abline(v = min_size_mars)
}
PlotAndSave(temp_plot_function, my_path_plot = paste(FIGURES_FOLDER_RELATIVE_PATH,
"mars_gcv_plot.jpeg",
collapse = ""))
df_metrics = Add_Test_Metric(df_metrics,
"MARS",
USED.Metrics(predict(mars_step, x = X_mm_no_interaction_vvv),
vvv$y,
weights = MY_WEIGHTS_vvv))
df_metrics
# save the df_metrics as .Rdata
save(df_metrics, file = "df_metrics.Rdata")
file_name_mars_step = paste(MODELS_FOLDER_RELATIVE_PATH,
"mars_step",
".Rdata", collapse = "", sep = "")
save(mars_step, file = file_name_mars_step)
rm(mars_step)
gc()
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
# PPR ------------------------------------
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
# max number of ridge functions
PPR_MAX_RIDGE_FUNCTIONS = 4
# possible spline degrees of freedom
PPR_DF_SM = 2:6
# given a list with elements parameters
# number of  ridge_functions
# spline degrees of freedom
# 1.a) Regulation: train - test ---------
#' @param my_data (data.frame)
#' @param my_id_train (vector of ints)
#' @param my_max_ridge_functions (vector of ints)
#' @param my_spline_df (vector in mums): values of possibile smoothing splines degrees of freedom
#' @param my_metrics_names (vector of chars)
#' @param my_weights (vector of nums):
#'  same length as the difference: NROW(my_data) - length(my_id_train)
#'
#' @return (array):
#' first dimension (with names): 1:my_max_ridge_functions
#' second dimension (with names): my_spline_df
#' third dimension (with names): my_metrics_names
#'
#' each cell contains the metric value of the model fitted on my_data[my_id_train,]
#' and tested on my_data[-my_id_train,] for each metric value used
PPRRegulationTrainTest = function(my_data = sss,
my_id_train = id_cb1,
my_max_ridge_functions = PPR_MAX_RIDGE_FUNCTIONS,
my_spline_df = PPR_DF_SM,
my_metrics_names = METRICS_NAMES,
my_weights = MY_WEIGHTS_sss){
metrics_array = array(NA,
dim = c(my_max_ridge_functions,
length(my_spline_df),
length(my_metrics_names)),
dimnames = list(1:my_max_ridge_functions,
my_spline_df,
my_metrics_names))
for(r in 1:my_max_ridge_functions){
for(df in 1: length(my_spline_df)){
mod = ppr(y ~ .,
data = my_data[my_id_train,],
nterms = r,
sm.method = "spline",
df = my_spline_df[df])
metrics_array[r, df, ] = USED.Metrics(predict(mod, my_data[-my_id_train,]),
my_data$y[-my_id_train],
weights = my_weights)
}
print(paste0("n ridge functions: ", r, collapse = ""))
}
rm(mod)
gc()
return(metrics_array)
}
#' @param my_data (data.frame)
#' @param my_id_train (vector of ints)
#' @param my_max_ridge_functions (vector of ints)
#' @param my_spline_df (vector in mums): values of possibile smoothing splines degrees of freedom
#' @param my_metrics_names (vector of chars)
#' @param my_weights (vector of nums):
#'  same length as the difference: NROW(my_data) - length(my_id_train)
#'
#'
#' @param my_metrics_functions (vector of characters): vector of loss function names feed to snowfall (parallel)
#' example  my_metrics_functions = c("USED.Metrics", "MAE.Loss", "MSE.Loss").
#' NOTE: if USED.Metrics contains some other functions they must be present as well, like the example
#' which is also the default
#' @param my_ncores
#'
#' @return (array):
#' first dimension (with names): 1:my_max_ridge_functions
#' second dimension (with names): my_spline_df
#' third dimension (with names): my_metrics_names
#'
#' each cell contains the metric value of the model fitted on my_data[my_id_train,]
#' and tested on my_data[-my_id_train,] for each metric value used
PPRRegulationTrainTestParallel = function(my_data = sss,
my_id_train = id_cb1,
my_max_ridge_functions = PPR_MAX_RIDGE_FUNCTIONS,
my_spline_df = PPR_DF_SM,
my_metrics_names = METRICS_NAMES,
my_weights = MY_WEIGHTS_sss,
my_metrics_functions = MY_USED_METRICS,
my_ncores = N_CORES){
metrics_array = array(NA,
dim = c(my_max_ridge_functions,
length(my_spline_df),
length(my_metrics_names)),
dimnames = list(1:my_max_ridge_functions,
my_spline_df,
my_metrics_names))
my_n_metrics = length(my_metrics_names)
# needed to do parallel
# each list element contains a vector of length 2
# first element is the number of ridge functions
# second element are the spline degrees of freedom
params_list = list()
counter = 1
for (r in 1:my_max_ridge_functions){
for(df in my_spline_df){
params_list[[counter]] = c(r, df)
counter = counter + 1
}
}
# init parallel
sfInit(cpus = my_ncores, parallel = T)
sfExport(list = c("my_data", my_metrics_functions,
"my_id_train", "my_max_ridge_functions", "my_spline_df", "params_list",
"my_weights"))
temp_metric = sfLapply(params_list,
fun = function(el)
USED.Metrics(predict(ppr(y ~ .,
data = my_data[my_id_train,],
nterms = el[1],
sm.method = "spline",
df = el[2]),
my_data[-my_id_train,]), my_data$y[-my_id_train],
weights = my_weights))
# stop cluster
sfStop()
counter = 1
for (r in 1:my_max_ridge_functions){
for(df in 1:length(my_spline_df)){
metrics_array[r, df, ] = temp_metric[[counter]]
counter = counter + 1
}
}
rm(temp_metric)
gc()
return(metrics_array)
}
# ppr_metrics = PPRRegulationTrainTestParallel(my_data = sss,
#                                              my_id_train = id_cb1,
#                                              my_max_ridge_functions = PPR_MAX_RIDGE_FUNCTIONS,
#                                              my_spline_df = PPR_DF_SM,
#                                              my_metrics_names = METRICS_NAMES,
#                                              my_weights = MY_WEIGHTS_sss,
#                                              my_metrics_functions = MY_USED_METRICS,
#                                              my_ncores = N_CORES)
# 1.b) Regulation: CV -------
ppr_metrics = PPRRegulationCVParallel(my_data = sss,
my_id_list_cv = ID_CV_LIST,
my_max_ridge_functions = PPR_MAX_RIDGE_FUNCTIONS,
my_spline_df = PPR_DF_SM,
my_metrics_names = METRICS_NAMES,
my_weights = MY_WEIGHTS_sss,
my_metrics_functions = MY_USED_METRICS,
my_ncores = N_CORES,
use_only_first_fold = TRUE)
# 2) final model -------
ppr_best_params = PPRExtractBestParams(ppr_metrics)
ppr_best_params
ppr_metrics
#'
#' WARNING, pay attention to this parameter:
#' @param indexes_metric_max (vector of ints): indexes for which high metric values is best (ex f1 score)
#' (default NULL)
#'
#' @return (list):nested list: first level elements are metrics names
#' for each metric name three elements are given:
#' 1) best value of ridge functions number: accessed by ridge_fun_num
#' 2) best value of spline equivalent degrees of freedom: accessed by spline_df
#' 3) the metric value (minimum or maximum, depending on context) associated with 1) and 2)
PPRExtractBestParams = function(my_metrics_array,
indexes_metric_max = NULL){
# first build the matrix of indexes
# this is needed since below the which.min and which.max
# functions return the index of the vectorized matrix
# hence we need to retrieve the row and column given the index
n_row_metrics = NROW(my_metrics_array[,,1])
n_col_metrics = NCOL(my_metrics_array[,,1])
n_ridge_functions_values = as.numeric(rownames(my_metrics_array[,,1]))
spline_df_values = as.numeric(colnames(my_metrics_array[,,1]))
indexes_matrix = matrix(1:(n_row_metrics * n_col_metrics),
nrow = n_row_metrics,
ncol = n_col_metrics)
# Check metrics min and max best
metrics_names = dimnames(my_metrics_array)[[3]]
indexes_metrics = length(metrics_names)
returned_best_list = list(metrics_names)
for(i in 1:indexes_metrics){
if(i %in% indexes_metric_max){
# index of best cell with matrix as vector
temp_best_index = which.max(my_metrics_array[,,i])
}
else{
# index of best cell with matrix as vector
temp_best_index = which.min(my_metrics_array[,,i])
}
# get the indexes of the matrix
print(temp_best_index)
temp_index_col = temp_best_index %/% n_row_metrics + temp_best_index %% n_row_metrics
print(temp_index_col)
temp_index_row = which(indexes_matrix[,temp_index_col] == temp_best_index)
# save the optimal values
returned_best_list[[metrics_names[i]]][["n_ridge_functions"]] = n_ridge_functions_values[temp_index_row]
returned_best_list[[metrics_names[i]]][["spline_df"]] = spline_df_values[temp_index_col]
returned_best_list[[metrics_names[i]]][["metric_value"]] = my_metrics_array[temp_index_row,
temp_index_col,
i]
}
return(returned_best_list)
}
ppr_best_params = PPRExtractBestParams(ppr_metrics)
ppr_metrics
min(ppr_metrics[,,"MAE"])
18 %/% 4
18 %% 4
#'
#' WARNING, pay attention to this parameter:
#' @param indexes_metric_max (vector of ints): indexes for which high metric values is best (ex f1 score)
#' (default NULL)
#'
#' @return (list):nested list: first level elements are metrics names
#' for each metric name three elements are given:
#' 1) best value of ridge functions number: accessed by ridge_fun_num
#' 2) best value of spline equivalent degrees of freedom: accessed by spline_df
#' 3) the metric value (minimum or maximum, depending on context) associated with 1) and 2)
PPRExtractBestParams = function(my_metrics_array,
indexes_metric_max = NULL){
# first build the matrix of indexes
# this is needed since below the which.min and which.max
# functions return the index of the vectorized matrix
# hence we need to retrieve the row and column given the index
n_row_metrics = NROW(my_metrics_array[,,1])
n_col_metrics = NCOL(my_metrics_array[,,1])
n_ridge_functions_values = as.numeric(rownames(my_metrics_array[,,1]))
spline_df_values = as.numeric(colnames(my_metrics_array[,,1]))
indexes_matrix = matrix(1:(n_row_metrics * n_col_metrics),
nrow = n_row_metrics,
ncol = n_col_metrics)
# Check metrics min and max best
metrics_names = dimnames(my_metrics_array)[[3]]
indexes_metrics = length(metrics_names)
returned_best_list = list(metrics_names)
for(i in 1:indexes_metrics){
if(i %in% indexes_metric_max){
# index of best cell with matrix as vector
temp_best_index = which.max(my_metrics_array[,,i])
}
else{
# index of best cell with matrix as vector
temp_best_index = which.min(my_metrics_array[,,i])
}
# get the indexes of the matrix
print(temp_best_index)
temp_index_col = temp_best_index %/% n_row_metrics + ((temp_best_index %% n_row_metrics) > 0)
print(temp_index_col)
temp_index_row = which(indexes_matrix[,temp_index_col] == temp_best_index)
# save the optimal values
returned_best_list[[metrics_names[i]]][["n_ridge_functions"]] = n_ridge_functions_values[temp_index_row]
returned_best_list[[metrics_names[i]]][["spline_df"]] = spline_df_values[temp_index_col]
returned_best_list[[metrics_names[i]]][["metric_value"]] = my_metrics_array[temp_index_row,
temp_index_col,
i]
}
return(returned_best_list)
}
ppr_best_params = PPRExtractBestParams(ppr_metrics)
ppr_best_params
#'
#' WARNING, pay attention to this parameter:
#' @param indexes_metric_max (vector of ints): indexes for which high metric values is best (ex f1 score)
#' (default NULL)
#'
#' @return (list):nested list: first level elements are metrics names
#' for each metric name three elements are given:
#' 1) best value of ridge functions number: accessed by ridge_fun_num
#' 2) best value of spline equivalent degrees of freedom: accessed by spline_df
#' 3) the metric value (minimum or maximum, depending on context) associated with 1) and 2)
PPRExtractBestParams = function(my_metrics_array,
indexes_metric_max = NULL){
# first build the matrix of indexes
# this is needed since below the which.min and which.max
# functions return the index of the vectorized matrix
# hence we need to retrieve the row and column given the index
n_row_metrics = NROW(my_metrics_array[,,1])
n_col_metrics = NCOL(my_metrics_array[,,1])
n_ridge_functions_values = as.numeric(rownames(my_metrics_array[,,1]))
spline_df_values = as.numeric(colnames(my_metrics_array[,,1]))
indexes_matrix = matrix(1:(n_row_metrics * n_col_metrics),
nrow = n_row_metrics,
ncol = n_col_metrics)
# Check metrics min and max best
metrics_names = dimnames(my_metrics_array)[[3]]
indexes_metrics = length(metrics_names)
returned_best_list = list(metrics_names)
for(i in 1:indexes_metrics){
if(i %in% indexes_metric_max){
# index of best cell with matrix as vector
temp_best_index = which.max(my_metrics_array[,,i])
}
else{
# index of best cell with matrix as vector
temp_best_index = which.min(my_metrics_array[,,i])
}
# get the indexes of the matrix
temp_index_col = temp_best_index %/% n_row_metrics + ((temp_best_index %% n_row_metrics) > 0)
temp_index_row = which(indexes_matrix[,temp_index_col] == temp_best_index)
# save the optimal values
returned_best_list[[metrics_names[i]]][["n_ridge_functions"]] = n_ridge_functions_values[temp_index_row]
returned_best_list[[metrics_names[i]]][["spline_df"]] = spline_df_values[temp_index_col]
returned_best_list[[metrics_names[i]]][["metric_value"]] = my_metrics_array[temp_index_row,
temp_index_col,
i]
}
return(returned_best_list)
}
print("ppr best params")
ppr_best_params
ppr_model = ppr(y ~ .,
data = sss,
nterms = ppr_best_params[[METRIC_CHOSEN_NAME]][["n_ridge_functions"]],
sm.method = "spline",
df = ppr_best_params[[METRIC_CHOSEN_NAME]][["spline_df"]])
df_metrics = Add_Test_Metric(df_metrics,
"PPR",
USED.Metrics(predict(ppr_model, vvv),
vvv$y,
weights = MY_WEIGHTS_vvv))
df_metrics
# save the df_metrics as .Rdata
save(df_metrics, file = "df_metrics.Rdata")
file_name_ppr_model = paste(MODELS_FOLDER_RELATIVE_PATH,
"ppr_model",
".Rdata", collapse = "", sep = "")
save(ppr_model, file = file_name_ppr_model)
rm(ppr_model)
gc()
df_metrics
rm(gam0)
gc()
