my_max_size = TREE_MAX_SIZE,
my_weights = 1,
my_metrics_functions = MY_USED_METRICS,
my_ncores = N_CORES,
my_mindev = 1e-05,
my_minsize = 2,
use_only_first_fold = FALSE,
is_classification = FALSE,
my_threshold = 0.5,
is_multiclass = FALSE){
n_k_fold = length(my_id_list_cv)
my_n_metrics = length(my_metric_names)
all_fold_indexes = 1:n_k_fold
# this are the indexed of the folds used as test set
# default all are used once as test set
fold_used_as_test_indexes = 1:length(my_id_list_cv)
# if only the first fold is used a test set
if(use_only_first_fold == TRUE){
fold_used_as_test_indexes = 1
}
# init parallel
sfInit(cpus = my_ncores, parallel = T)
sfLibrary(tree)
sfExport(list = c("my_data", my_metrics_functions,
"my_weights", "my_max_size",
"is_classification","my_threshold",
"is_multiclass", "my_mindev", "my_minsize"))
# we use my_max_size - 1 because we start with size = 2
temp_metrics_array_cv = array(NA, dim = c(n_k_fold, my_max_size - 1, my_n_metrics))
for (k in fold_used_as_test_indexes) {
# k-th fold set is used as validation set
id_test = my_id_list_cv[[k]]
# one set among those remaining is chosen as the pruning set
# specifically we choose the one corresponding to the one with the minimum index
# among those not in the validation set
# if the test set is the first index choose the last set a pruning set
# else choose the test index set - 1 as pruning set
if(k == 1){
index_id_pruning = n_k_fold
}
if(k > 1){
index_id_pruning = k - 1
}
id_pruning = my_id_list_cv[[index_id_pruning]]
# the remaining fold sets are used as training set
id_train = unlist(my_id_list_cv[-c(k, index_id_pruning)])
# full grown tree
temp_tree_full = tree(y ~.,
data = my_data[id_train,],
control = tree.control(nobs = length(id_train),
mindev = my_mindev,
minsize = my_minsize))
if(is_classification == TRUE){
temp_tree_full = tree(factor(y) ~.,
data = my_data[id_train,],
control = tree.control(nobs = length(id_train),
mindev = my_mindev,
minsize = my_minsize))
}
# it has to overfit
plot(temp_tree_full)
#' @param size (num): size values
#' @return (vector of nums): metrics values
ParallelFunction = function(size){
temp_tree_pruned = prune.tree(temp_tree_full,
best = size,
newdata = my_data[id_pruning,])
if(is_multiclass == TRUE){
temp_predictions = predict(temp_tree_pruned,
newdata = my_data[id_test,],
type = "class")
}
# default
if(is_multiclass == FALSE){
temp_predictions = predict(temp_tree_pruned, newdata = my_data[id_test,])
}
if((is_classification == TRUE) & (is_multiclass == FALSE)){
# tree gives probabilities for each class
positive_index = which(colnames(temp_predictions) == 1)
temp_predictions = temp_predictions[,positive_index] > my_threshold
}
return(USED.Metrics(y.pred = temp_predictions,
y.test = my_data$y[id_test],
weights = my_weights[id_test]))
}
sfExport(list = c("temp_tree_full",
"id_train", "id_test", "id_pruning",
"ParallelFunction"))
temp_metrics = sfLapply(2:my_max_size,
fun = ParallelFunction)
# unlist to the right dimensions matrix
temp_metrics_array_cv[k,,] = matrix(unlist(temp_metrics),
nrow = length(my_max_size) - 1,
ncol = my_n_metrics,
byrow = T)
rm(temp_metrics)
gc()
print(paste("fold ", k))
}
# averaged metrics matrix
cv_metrics = matrix(NA, nrow = my_max_size - 1, ncol = my_n_metrics)
# metrics standard deviations matrix
cv_metrics_se = matrix(NA, nrow = my_max_size - 1, ncol = my_n_metrics)
colnames(cv_metrics) = my_metric_names
colnames(cv_metrics_se) = my_metric_names
for (i in 1:my_n_metrics){
if(use_only_first_fold == FALSE){
cv_metrics[,i] = apply(temp_metrics_array_cv[,,i], 2, mean)
cv_metrics_se[,i] = apply(temp_metrics_array_cv[,,i], 2, sd)}
if(use_only_first_fold == TRUE){
cv_metrics[,i] = temp_metrics_array_cv[1,,i]
cv_metrics_se[,i] = 0
}
}
return(list("metrics" = cv_metrics,
"se" = cv_metrics_se))
}
# if parallel shows problems use the non parallel version
tree_cv_metrics = ManualCvTreeParallel2(my_id_list_cv = ID_CV_LIST,
my_metric_names = METRICS_NAMES,
my_data = sss,
my_max_size = TREE_MAX_SIZE,
my_metrics_functions = MY_USED_METRICS,
my_ncores = N_CORES,
my_weights = MY_WEIGHTS_sss,
my_mindev = 1e-04,
my_minsize = 5,
use_only_first_fold = USE_ONLY_FIRST_FOLD,
is_classification = TRUE,
my_threshold = MY_THRESHOLD)
#'
#' @param is_classification (bool): if TRUE adapt the metrics to classification problem
#' using the threshold
#' @param my_threshold (num): classification threshold used
#'
#' @param is_multiclass (bool): multiclass classification (to be checked)
#'
#' @param my_max_size (int): max size of the pruned tree
#'
#' @return matrix of CV folds averaged errors for each parameter value and each loss function
ManualCvTreeParallel2 = function(my_id_list_cv,
my_metric_names,
my_data,
my_max_size = TREE_MAX_SIZE,
my_weights = 1,
my_metrics_functions = MY_USED_METRICS,
my_ncores = N_CORES,
my_mindev = 1e-05,
my_minsize = 2,
use_only_first_fold = FALSE,
is_classification = FALSE,
my_threshold = 0.5,
is_multiclass = FALSE){
n_k_fold = length(my_id_list_cv)
my_n_metrics = length(my_metric_names)
all_fold_indexes = 1:n_k_fold
# this are the indexed of the folds used as test set
# default all are used once as test set
fold_used_as_test_indexes = 1:length(my_id_list_cv)
# if only the first fold is used a test set
if(use_only_first_fold == TRUE){
fold_used_as_test_indexes = 1
}
# init parallel
sfInit(cpus = my_ncores, parallel = T)
sfLibrary(tree)
sfExport(list = c("my_data", my_metrics_functions,
"my_weights", "my_max_size",
"is_classification","my_threshold",
"is_multiclass", "my_mindev", "my_minsize"))
# we use my_max_size - 1 because we start with size = 2
temp_metrics_array_cv = array(NA, dim = c(n_k_fold, my_max_size - 1, my_n_metrics))
for (k in fold_used_as_test_indexes) {
# k-th fold set is used as validation set
id_test = my_id_list_cv[[k]]
# one set among those remaining is chosen as the pruning set
# specifically we choose the one corresponding to the one with the minimum index
# among those not in the validation set
# if the test set is the first index choose the last set a pruning set
# else choose the test index set - 1 as pruning set
if(k == 1){
index_id_pruning = n_k_fold
}
if(k > 1){
index_id_pruning = k - 1
}
id_pruning = my_id_list_cv[[index_id_pruning]]
# the remaining fold sets are used as training set
id_train = unlist(my_id_list_cv[-c(k, index_id_pruning)])
# full grown tree
temp_tree_full = tree(y ~.,
data = my_data[id_train,],
control = tree.control(nobs = length(id_train),
mindev = my_mindev,
minsize = my_minsize))
if(is_classification == TRUE){
temp_tree_full = tree(factor(y) ~.,
data = my_data[id_train,],
control = tree.control(nobs = length(id_train),
mindev = my_mindev,
minsize = my_minsize))
}
# it has to overfit
plot(temp_tree_full)
#' @param size (num): size values
#' @return (vector of nums): metrics values
ParallelFunction = function(size){
temp_tree_pruned = prune.tree(temp_tree_full,
best = size,
newdata = my_data[id_pruning,])
if(is_multiclass == TRUE){
temp_predictions = predict(temp_tree_pruned,
newdata = my_data[id_test,],
type = "class")
}
# default
if(is_multiclass == FALSE){
temp_predictions = predict(temp_tree_pruned, newdata = my_data[id_test,])
}
if((is_classification == TRUE) & (is_multiclass == FALSE)){
# tree gives probabilities for each class
positive_index = which(colnames(temp_predictions) == 1)
temp_predictions = temp_predictions[,positive_index] > my_threshold
}
return(USED.Metrics(y.pred = temp_predictions,
y.test = my_data$y[id_test],
weights = my_weights[id_test]))
}
sfExport(list = c("temp_tree_full",
"id_train", "id_test", "id_pruning",
"ParallelFunction"))
temp_metrics = sfLapply(2:my_max_size,
fun = ParallelFunction)
# unlist to the right dimensions matrix
temp_metrics_array_cv[k,,] = matrix(unlist(temp_metrics),
nrow = my_max_size - 1,
ncol = my_n_metrics,
byrow = T)
rm(temp_metrics)
gc()
print(paste("fold ", k))
}
# averaged metrics matrix
cv_metrics = matrix(NA, nrow = my_max_size - 1, ncol = my_n_metrics)
# metrics standard deviations matrix
cv_metrics_se = matrix(NA, nrow = my_max_size - 1, ncol = my_n_metrics)
colnames(cv_metrics) = my_metric_names
colnames(cv_metrics_se) = my_metric_names
for (i in 1:my_n_metrics){
if(use_only_first_fold == FALSE){
cv_metrics[,i] = apply(temp_metrics_array_cv[,,i], 2, mean)
cv_metrics_se[,i] = apply(temp_metrics_array_cv[,,i], 2, sd)}
if(use_only_first_fold == TRUE){
cv_metrics[,i] = temp_metrics_array_cv[1,,i]
cv_metrics_se[,i] = 0
}
}
return(list("metrics" = cv_metrics,
"se" = cv_metrics_se))
}
# if parallel shows problems use the non parallel version
tree_cv_metrics = ManualCvTreeParallel2(my_id_list_cv = ID_CV_LIST,
my_metric_names = METRICS_NAMES,
my_data = sss,
my_max_size = TREE_MAX_SIZE,
my_metrics_functions = MY_USED_METRICS,
my_ncores = N_CORES,
my_weights = MY_WEIGHTS_sss,
my_mindev = 1e-04,
my_minsize = 5,
use_only_first_fold = USE_ONLY_FIRST_FOLD,
is_classification = TRUE,
my_threshold = MY_THRESHOLD)
tree_cv_metrics
tree_best_summary = CvMetricBest(my_param_values = 2:TREE_MAX_SIZE,
my_metric_matrix = tree_cv_metrics[["metrics"]],
my_one_se_best = TRUE,
my_higher_more_complex = TRUE,
my_se_matrix = tree_cv_metrics[["se"]],
my_metric_names = METRICS_NAMES,
indexes_metric_max = 4)
PlotAndSave(function()(
PlotCvMetrics(my_param_values = 2:TREE_MAX_SIZE,
my_metric_matrix = tree_cv_metrics[["metrics"]],
my_se_matrix = tree_cv_metrics[["se"]],
my_best_param_values = ExtractBestParams(tree_best_summary),
my_metric_names = METRICS_NAMES,
my_main = "Tree CV metrics",
my_xlab = "size")),
my_path_plot = paste(FIGURES_FOLDER_RELATIVE_PATH,
"tree_cv_metrics_plot.jpeg",
collapse = ""))
#' @param my_metrics_functions (vector of characters): vector of loss function names feed to snowfall (parallel)
#' example  my_metrics_functions = c("USED.Metrics", "MAE.Loss", "MSE.Loss").
#' NOTE: if USED.Metrics contains some other functions they must be present as well, like the example
#' which is also the default
#'
#' @return matrix of CV folds averaged errors for each parameter value and each loss function
ManualCvTreeParallel = function(my_id_list_cv,
my_metric_names,
my_data,
my_max_size = TREE_MAX_SIZE,
my_weights = 1,
my_metrics_functions = MY_USED_METRICS,
my_ncores = N_CORES,
my_mindev = 1e-05,
my_minsize = 2,
use_only_first_fold = FALSE,
is_classification = FALSE,
my_threshold = 0.5,
is_multiclass = FALSE){
n_k_fold = length(my_id_list_cv)
my_n_metrics = length(my_metric_names)
all_fold_indexes = 1:n_k_fold
# this are the indexed of the folds used as test set
# default all are used once as test set
fold_used_as_test_indexes = 1:length(my_id_list_cv)
# if only the first fold is used a test set
if(use_only_first_fold == TRUE){
fold_used_as_test_indexes = 1
}
# init parallel
sfInit(cpus = my_ncores, parallel = T)
sfLibrary(tree)
sfExport(list = c("my_data", my_metrics_functions,
"my_weights", "my_max_size",
"is_classification","my_threshold",
"is_multiclass", "my_mindev", "my_minsize"))
# we use my_max_size - 1 because we start with size = 2
temp_metrics_array_cv = array(NA, dim = c(n_k_fold, my_max_size - 1, my_n_metrics))
for (k in fold_used_as_test_indexes) {
# k-th fold set is used as validation set
id_test = my_id_list_cv[[k]]
# one set among those remaining is chosen as the pruning set
# specifically we choose the one corresponding to the one with the minimum index
# among those not in the validation set
# if the test set is the first index choose the last set a pruning set
# else choose the test index set - 1 as pruning set
if(k == 1){
index_id_pruning = n_k_fold
}
if(k > 1){
index_id_pruning = k - 1
}
id_pruning = my_id_list_cv[[index_id_pruning]]
# the remaining fold sets are used as training set
id_train = unlist(my_id_list_cv[-c(k, index_id_pruning)])
# full grown tree
temp_tree_full = tree(y ~.,
data = my_data[id_train,],
control = tree.control(nobs = length(id_train),
mindev = my_mindev,
minsize = my_minsize))
if(is_classification == TRUE){
temp_tree_full = tree(factor(y) ~.,
data = my_data[id_train,],
control = tree.control(nobs = length(id_train),
mindev = my_mindev,
minsize = my_minsize))
}
# it has to overfit
plot(temp_tree_full)
#' @param size (num): size values
#' @return (vector of nums): metrics values
ParallelFunction = function(size){
temp_tree_pruned = prune.tree(temp_tree_full,
best = size,
newdata = my_data[id_pruning,])
if(is_multiclass == TRUE){
temp_predictions = predict(temp_tree_pruned,
newdata = my_data[id_test,],
type = "class")
}
# default
if(is_multiclass == FALSE){
temp_predictions = predict(temp_tree_pruned, newdata = my_data[id_test,])
}
if((is_classification == TRUE) & (is_multiclass == FALSE)){
# tree gives probabilities for each class
positive_index = which(colnames(temp_predictions) == 1)
temp_predictions = temp_predictions[,positive_index] > my_threshold
}
return(USED.Metrics(y.pred = temp_predictions,
y.test = my_data$y[id_test],
weights = my_weights[id_test]))
}
sfExport(list = c("temp_tree_full",
"id_train", "id_test", "id_pruning",
"ParallelFunction"))
temp_metrics = sfLapply(2:my_max_size,
fun = ParallelFunction)
# unlist to the right dimensions matrix
temp_metrics_array_cv[k,,] = matrix(unlist(temp_metrics),
nrow = my_max_size - 1,
ncol = my_n_metrics,
byrow = T)
rm(temp_metrics)
gc()
print(paste("fold ", k))
}
# averaged metrics matrix
cv_metrics = matrix(NA, nrow = my_max_size - 1, ncol = my_n_metrics)
# metrics standard deviations matrix
cv_metrics_se = matrix(NA, nrow = my_max_size - 1, ncol = my_n_metrics)
colnames(cv_metrics) = my_metric_names
colnames(cv_metrics_se) = my_metric_names
for (i in 1:my_n_metrics){
if(use_only_first_fold == FALSE){
cv_metrics[,i] = apply(temp_metrics_array_cv[,,i], 2, mean)
cv_metrics_se[,i] = apply(temp_metrics_array_cv[,,i], 2, sd)}
if(use_only_first_fold == TRUE){
cv_metrics[,i] = temp_metrics_array_cv[1,,i]
cv_metrics_se[,i] = 0
}
}
return(list("metrics" = cv_metrics,
"se" = cv_metrics_se))
}
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
# Modello Additivo ---------------------------
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
library(gam)
# stepwise forward: AIC based on generalized df
gam0 = gam(y ~ 1, data = sss, family = "binomial")
# gam recognizes factor predictors
my_gam_scope = gam.scope(sss[,-y_index], arg = c("df=2", "df=3", "df=4", "df=5", "df=6"))
gam_step = step.Gam(gam0, scope = my_gam_scope)
temp_pred = predict(gam_step,
newdata = vvv,
type = "response")
head(temp_pred)
pred_list$gam_step = temp_pred
df_metrics = Add_Test_Metric(df_metrics,
"gam_step",
USED.Metrics(temp_pred > MY_THRESHOLD,
vvv$y,
weights = MY_WEIGHTS_vvv))
df_metrics
rm(temp_pred)
file_name_gam_step = paste(MODELS_FOLDER_RELATIVE_PATH,
"gam_step",
".Rdata", collapse = "", sep = "")
save(gam_step, file = file_name_gam_step)
rm(gam_step)
rm(gam0)
gc()
# save the df_metrics as .Rdata
save(df_metrics, pred_list, file = "df_metrics.Rdata")
# data.frame case
num_index = which(colnames(sss[,-y_index]) %in% var_num_names)
factor_index = setdiff(1:NCOL(sss[,-y_index]), num_index)
library(polspline)
?polymars()
mars_step = polymars(responses = sss$y,
predictors = sss[,-y_index],
gcv = 1,
factors = factor_index,
maxsize = 50,
classify = TRUE)
print("mars min size gcv")
min_size_mars = mars_step$fitting$size[which.min(mars_step$fitting$GCV)]
min_size_mars
temp_plot_function = function(){
plot(mars_step$fitting$size, mars_step$fitting$GCV,
col = as.factor(mars_step$fitting$`0/1`),
pch = 16,
xlab = "basis number",
ylab = "GCV",
main = "MARS step GCV")
legend(c("topright"),
legend = c("growing", "pruning"),
col = c("black","red"),
pch = 16)
abline(v = min_size_mars)
}
PlotAndSave(temp_plot_function, my_path_plot = paste(FIGURES_FOLDER_RELATIVE_PATH,
"mars_gcv_plot.jpeg",
collapse = ""))
?predict.polymars()
temp_pred = predict(mars_step, x = vvv[,-y_index])
head(temp_pred)
vvv$y[,1]
vvv$y[1]
# pay attention to the column
temp_pred = predict(mars_step, x = vvv[,-y_index])[,2]
pred_list$mars_step = temp_pred
df_metrics = Add_Test_Metric(df_metrics,
"MARS",
USED.Metrics(temp_pred > MY_THRESHOLD,
vvv$y,
weights = MY_WEIGHTS_vvv))
df_metrics
rm(temp_pred)
# save the df_metrics as .Rdata
save(df_metrics, pred_list, file = "df_metrics.Rdata")
mars_names = colnames(sss[,-y_index])
file_name_mars_step = paste(MODELS_FOLDER_RELATIVE_PATH,
"mars_step",
".Rdata", collapse = "", sep = "")
save(mars_step,
mars_names,
file = file_name_mars_step)
rm(mars_step)
gc()
load("mars_step.Rdata")
# MARS -----------------
load(paste(MODELS_FOLDER_RELATIVE_PATH,
"mars_step",
".Rdata", collapse = "", sep = ""))
mars_step$model
names(pred_list)
names(pred_list)
