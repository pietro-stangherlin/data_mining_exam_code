df_metrics = data.frame(name = NA,
misclassification = NA,
fp = NA,
fn = NA,
f_score = NA)
# lista previsioni (punteggi) (se stima - verifica)
# per LIFT e ROC
pred_list = list()
METRICS_NAMES = colnames(df_metrics[,-1])
N_METRICS = length(METRICS_NAMES)
# names used to extract the metric added to df_metrics
# change based on the spefific problem
METRIC_VALUES_NAME = "metric_values"
METRIC_CHOSEN_NAME = "f_score"
# names used for accessing list CV matrix (actual metrics and metrics se)
LIST_METRICS_ACCESS_NAME = "metrics"
LIST_SD_ACCESS_NAME = "se"
# metrics names + USED.Loss
# WARNING: the order should be same as in df_metrics
MY_USED_METRICS = c("USED.Metrics", "tabella.sommario")
# /////////////////////////////////////////////////////////////////
#------------------------ Train & Test ------------------------
# /////////////////////////////////////////////////////////////////
# eventually change the proportion
id_stima = sample(1:NROW(dati), 0.75 * NROW(dati))
sss = dati[id_stima,]
vvv = dati[-id_stima,]
# lista dei predittori (se stima - verifica)
# per LIFT e ROC
pred_list = list()
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
# Parameter tuning: Train & Test on Train subset  --------------
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
id_cb1 = sample(1:NROW(sss), 0.8 * NROW(sss))
# delete original data.frame from main memory
rm(dati)
gc()
# ///////////////////////////////////
# Weights ---------------
# //////////////////////////////////
# weights used for each metric function
# default 1
MY_WEIGHTS_sss = rep(1, NROW(sss))
MY_WEIGHTS_vvv = rep(1, NROW(vvv))
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
# Parameter tuning: cross validation on train: building cv folds  -------------------
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
K_FOLDS = 10
NROW_sss = NROW(sss)
SHUFFLED_ID = sample(1:NROW_sss, NROW_sss)
# NOTE: if the row number of sss is not a multiple of K_FOLDS
# the last fold repeats some ids from the first
# this is fixed in the code below
id_matrix_cv = matrix(SHUFFLED_ID, ncol = K_FOLDS)
# conversion of matrix in list of elements: each element contains a subset of ids
ID_CV_LIST = list()
for(j in 1:ncol(id_matrix_cv)){
ID_CV_LIST[[j]] = id_matrix_cv[,j]
}
rm(id_matrix_cv)
gc()
# repeated ids fixing
integer_division_cv = NROW_sss %/% K_FOLDS
modulo_cv = NROW_sss %% K_FOLDS
if(modulo_cv != 0){
ID_CV_LIST[[K_FOLDS]] = ID_CV_LIST[[K_FOLDS]][1:integer_division_cv]
}
source("cv_functions.R")
# FALSE = traditional CV on all folds
# TRUE -> use only first fold to test and all other to fit
USE_ONLY_FIRST_FOLD = FALSE
# /////////////////////////////////////////////////////////////////
#------------------------ Analisi esplorative ---------------------
# /////////////////////////////////////////////////////////////////
# Analisi esplorativa sulla stima
# eventuali inflazioni di zeri
# valutiamo se è sbilanciata
# ed eventualmente se è ragionevole cambiare la solita soglia a 0.5
table(sss$y)
# soglia di classificazione: cambia eventualmente con
# table(sss$y)[2] / NROW(sss)
MY_THRESHOLD = 0.2
# /////////////////////////////////////////////////////////////////
#------------------------ Modelli ---------------------------------
# /////////////////////////////////////////////////////////////////
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
# Classificazione Casuale --------------------
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
# modello classificazione casuale
df_metrics = Add_Test_Metric(df_metrics,
"sss threshold",
USED.Metrics(y.pred = rbinom(nrow(vvv), 1, MY_THRESHOLD),
y.test = vvv$y,
weights = MY_WEIGHTS_vvv))
df_metrics = na.omit(df_metrics)
df_metrics
ppr_metrics = PPRRegulationCVParallel(my_data = sss,
my_id_list_cv = ID_CV_LIST,
my_max_ridge_functions = PPR_MAX_RIDGE_FUNCTIONS,
my_spline_df = PPR_DF_SM,
my_metrics_names = METRICS_NAMES,
my_weights = MY_WEIGHTS_sss,
my_metrics_functions = MY_USED_METRICS,
my_ncores = N_CORES,
use_only_first_fold = TRUE)
ppr_metrics
ppr_metrics = PPRRegulationCVParallel(my_data = sss,
my_id_list_cv = ID_CV_LIST,
my_max_ridge_functions = PPR_MAX_RIDGE_FUNCTIONS,
my_spline_df = PPR_DF_SM,
my_metrics_names = METRICS_NAMES,
my_weights = MY_WEIGHTS_sss,
my_metrics_functions = MY_USED_METRICS,
my_threshold = MY_THRESHOLD,
my_ncores = N_CORES,
use_only_first_fold = TRUE)
ppr_metrics
#'
#' @return (array):
#' first dimension (with names): 1:my_max_ridge_functions
#' second dimension (with names): my_spline_df
#' third dimension (with names): my_metrics_names
#'
#' each cell contains the metric value of the model fitted on my_data[my_id_train,]
#' and tested on my_data[-my_id_train,] for each metric value used
#'
#TO FIX: classification ---------------
PPRRegulationCVParallel = function(my_data = sss,
my_id_list_cv,
my_max_ridge_functions = PPR_MAX_RIDGE_FUNCTIONS,
my_spline_df = PPR_DF_SM,
my_metrics_names = METRICS_NAMES,
my_weights = MY_WEIGHTS,
my_metrics_functions = MY_USED_METRICS,
my_ncores = N_CORES,
use_only_first_fold = FALSE,
is_classification = FALSE,
my_threshold = 0.5){
n_k_fold = length(my_id_list_cv)
my_n_metrics = length(my_metrics_names)
# needed to do parallel
# each list element contains a vector of length 2
# first element is the number of ridge functions
# second element are the spline degrees of freedom
params_list = list()
counter = 1
for (r in 1:my_max_ridge_functions){
for(df in my_spline_df){
params_list[[counter]] = c(r, df)
counter = counter + 1
}
}
# init parallel
sfInit(cpus = my_ncores, parallel = T)
sfExport(list = c("my_data", my_metrics_functions,
"my_max_ridge_functions", "my_spline_df", "params_list",
"my_weights", "is_classification", "my_threshold"))
temp_metrics_array_cv = array(0,
dim = c(my_max_ridge_functions,
length(my_spline_df),
length(my_metrics_names),
n_k_fold),
dimnames = list(1:my_max_ridge_functions,
my_spline_df,
my_metrics_names,
1:n_k_fold))
# do after array creation: inefficient but should work
if(use_only_first_fold == TRUE){
n_k_fold = 1
}
for (k in 1:n_k_fold){
id_train = unlist(my_id_list_cv[-k])
id_test = my_id_list_cv[[k]]
sfExport(list = c("id_train", "id_test"))
#' @params (vector of nums):
#' first element: number of ridge functions
#' second element number of spline degrees of freedom
ParallelFunction = function(params){
temp_predictions = predict(ppr(y ~ .,
data = my_data[id_train,],
nterms = params[1],
sm.method = "spline",
df = params[2]),
my_data[id_test,])
if(is_classification == TRUE){
temp_predictions = temp_predictions > my_threshold
}
return(temp_predictions)
}
sfExport(list = c("ParallelFunction"))
temp_predictions = sfLapply(params_list,
fun = ParallelFunction(params))
counter = 1
for (r in 1:my_max_ridge_functions){
for(df in 1:length(my_spline_df)){
temp_metrics_array_cv[r, df, ,k] = USED.Metrics(temp_predictions[[counter]],
my_data$y[id_test],
weights = my_weights[id_test])
counter = counter + 1
}
}
print(paste("fold = ", k, collapse = ""))
}
# stop cluster
sfStop()
metrics_array = array(0,
dim = c(my_max_ridge_functions,
length(my_spline_df),
length(my_metrics_names)),
dimnames = list(1:my_max_ridge_functions,
my_spline_df,
my_metrics_names))
# average over ridge functions
for(k in 1:n_k_fold){
metrics_array = metrics_array + temp_metrics_array_cv[, , ,k]
}
metrics_array = metrics_array / n_k_fold
gc()
return(metrics_array)
}
ppr_metrics = PPRRegulationCVParallel(my_data = sss,
my_id_list_cv = ID_CV_LIST,
my_max_ridge_functions = PPR_MAX_RIDGE_FUNCTIONS,
my_spline_df = PPR_DF_SM,
my_metrics_names = METRICS_NAMES,
my_weights = MY_WEIGHTS_sss,
my_metrics_functions = MY_USED_METRICS,
my_threshold = MY_THRESHOLD,
my_ncores = N_CORES,
use_only_first_fold = TRUE)
#'
#' @return (array):
#' first dimension (with names): 1:my_max_ridge_functions
#' second dimension (with names): my_spline_df
#' third dimension (with names): my_metrics_names
#'
#' each cell contains the metric value of the model fitted on my_data[my_id_train,]
#' and tested on my_data[-my_id_train,] for each metric value used
#'
#TO FIX: classification ---------------
PPRRegulationCVParallel = function(my_data = sss,
my_id_list_cv,
my_max_ridge_functions = PPR_MAX_RIDGE_FUNCTIONS,
my_spline_df = PPR_DF_SM,
my_metrics_names = METRICS_NAMES,
my_weights = MY_WEIGHTS,
my_metrics_functions = MY_USED_METRICS,
my_ncores = N_CORES,
use_only_first_fold = FALSE,
is_classification = FALSE,
my_threshold = 0.5){
n_k_fold = length(my_id_list_cv)
my_n_metrics = length(my_metrics_names)
# needed to do parallel
# each list element contains a vector of length 2
# first element is the number of ridge functions
# second element are the spline degrees of freedom
params_list = list()
counter = 1
for (r in 1:my_max_ridge_functions){
for(df in my_spline_df){
params_list[[counter]] = c(r, df)
counter = counter + 1
}
}
# init parallel
sfInit(cpus = my_ncores, parallel = T)
sfExport(list = c("my_data", my_metrics_functions,
"my_max_ridge_functions", "my_spline_df", "params_list",
"my_weights", "is_classification", "my_threshold"))
temp_metrics_array_cv = array(0,
dim = c(my_max_ridge_functions,
length(my_spline_df),
length(my_metrics_names),
n_k_fold),
dimnames = list(1:my_max_ridge_functions,
my_spline_df,
my_metrics_names,
1:n_k_fold))
# do after array creation: inefficient but should work
if(use_only_first_fold == TRUE){
n_k_fold = 1
}
for (k in 1:n_k_fold){
id_train = unlist(my_id_list_cv[-k])
id_test = my_id_list_cv[[k]]
sfExport(list = c("id_train", "id_test"))
#' @params (vector of nums):
#' first element: number of ridge functions
#' second element number of spline degrees of freedom
ParallelFunction = function(params){
temp_predictions = predict(ppr(y ~ .,
data = my_data[id_train,],
nterms = params[1],
sm.method = "spline",
df = params[2]),
my_data[id_test,])
if(is_classification == TRUE){
temp_predictions = temp_predictions > my_threshold
}
return(temp_predictions)
}
sfExport(list = c("ParallelFunction"))
temp_predictions = sfLapply(params_list,
fun = ParallelFunction)
counter = 1
for (r in 1:my_max_ridge_functions){
for(df in 1:length(my_spline_df)){
temp_metrics_array_cv[r, df, ,k] = USED.Metrics(temp_predictions[[counter]],
my_data$y[id_test],
weights = my_weights[id_test])
counter = counter + 1
}
}
print(paste("fold = ", k, collapse = ""))
}
# stop cluster
sfStop()
metrics_array = array(0,
dim = c(my_max_ridge_functions,
length(my_spline_df),
length(my_metrics_names)),
dimnames = list(1:my_max_ridge_functions,
my_spline_df,
my_metrics_names))
# average over ridge functions
for(k in 1:n_k_fold){
metrics_array = metrics_array + temp_metrics_array_cv[, , ,k]
}
metrics_array = metrics_array / n_k_fold
gc()
return(metrics_array)
}
ppr_metrics = PPRRegulationCVParallel(my_data = sss,
my_id_list_cv = ID_CV_LIST,
my_max_ridge_functions = PPR_MAX_RIDGE_FUNCTIONS,
my_spline_df = PPR_DF_SM,
my_metrics_names = METRICS_NAMES,
my_weights = MY_WEIGHTS_sss,
my_metrics_functions = MY_USED_METRICS,
my_threshold = MY_THRESHOLD,
my_ncores = N_CORES,
use_only_first_fold = TRUE)
ppr_metrics
ppr_metrics = PPRRegulationCVParallel(my_data = sss,
my_id_list_cv = ID_CV_LIST,
my_max_ridge_functions = PPR_MAX_RIDGE_FUNCTIONS,
my_spline_df = PPR_DF_SM,
my_metrics_names = METRICS_NAMES,
my_weights = MY_WEIGHTS_sss,
my_metrics_functions = MY_USED_METRICS,
my_ncores = N_CORES,
use_only_first_fold = TRUE,
is_classification = TRUE,
my_threshold = MY_THRESHOLD)
ppr_metrics
ppr_best_params = PPRExtractBestParams(ppr_metrics)
print("ppr best params")
ppr_best_params
ppr_model = ppr(y ~ .,
data = sss,
nterms = ppr_best_params[[METRIC_CHOSEN_NAME]][["n_ridge_functions"]],
sm.method = "spline",
df = ppr_best_params[[METRIC_CHOSEN_NAME]][["spline_df"]])
temp_pred = predict(ppr_model, vvv)
pred_list$ppr_model = temp_pred
df_metrics = Add_Test_Metric(df_metrics,
"PPR",
USED.Metrics(temp_pred > MY_THRESHOLD,
vvv$y,
weights = MY_WEIGHTS_vvv))
df_metrics
rm(temp_pred)
# save the df_metrics as .Rdata
save(df_metrics, pred_list, file = "df_metrics.Rdata")
file_name_ppr_model = paste(MODELS_FOLDER_RELATIVE_PATH,
"ppr_model",
".Rdata", collapse = "", sep = "")
save(ppr_model, file = file_name_ppr_model)
rm(ppr_model)
gc()
# Implementazione in parallelo
library(ranger)
library(snowfall)
sfInit(cpus = N_CORES, parallel = T)
sfLibrary(ranger)
sfExport(list = c("sss"))
# Implementazione in parallelo
library(ranger)
?ranger()
# massimo numero di esplicative presenti
m_max = NCOL(sss) - 1 # sottraggo 1 per la variabile risposta
# regolazione
# procedura sub-ottimale, ma la impiego per ragioni computazionali
# prima scelgo il numero di esplicative a ogni split,
# una volta scelto controllo la convergenza dell'errore basata sul numero di alberi
err = rep(NA, m_max)
for(i in seq(2, m_max)){
sfExport(list = c("i"))
err[i] = sum(sfSapply(rep(1:8),
function(x) ranger(factor(y) ~., data = sss,
mtry = i,
num.trees = 50,
probability = TRUE,
oob.error = TRUE)$prediction.error))
print(paste("mtry: ", i, collapse = ""))
gc()
}
print("Random forest error for each mtry")
err
best_mtry = which.min(err)
print("best mtry random forest")
best_mtry
sfExport(list = c("best_mtry"))
err_rf_trees = rep(NA, 90)
# °°°°°°°°°°°°°°°°°°°°°°°°°°°Warning: lento°°°°°°°°°°°°°°°°°°°°°°°°°°°°
for(j in 10:100){
sfExport(list = c("j"))
err_rf_trees[j] = sum(sfSapply(rep(1:4),
function(x) ranger(factor(y) ~., sss,
mtry = best_mtry,
num.trees = j,
probability = TRUE,
oob.error = TRUE)$prediction.error))
print(paste("number of trees: ", j, collapse = ""))
gc()
}
sfStop()
PlotAndSave(my_plotting_function =  function()plot((1:length(err_rf_trees)) * 4, err_rf_trees,
xlab = "Bootstrap trees number",
ylab = "Out of bag Error",
pch = 16,
main = "Random Forest"),
my_path_plot = paste(FIGURES_FOLDER_RELATIVE_PATH,
"random_forest_convergence_plot.jpeg",
collapse = ""))
# modello finale e previsioni
random_forest_model = ranger(factor(y) ~., sss,
mtry = best_mtry,
num.trees = 400,
oob.error = TRUE,
probability = TRUE,
importance = "permutation")
temp_pred = predict(random_forest_model, data = vvv,
type = "response")$predictions
pred_list$random_forest = temp_pred
df_metrics = Add_Test_Metric(df_metrics,
"Random Forest",
USED.Metrics(temp_pred > MY_THRESHOLD,
vvv$y,
weights = MY_WEIGHTS_vvv))
head(temp_pred)
# Warning check index
temp_pred = predict(random_forest_model, data = vvv,
type = "response")$predictions[,1]
pred_list$random_forest = temp_pred
df_metrics = Add_Test_Metric(df_metrics,
"Random Forest",
USED.Metrics(temp_pred > MY_THRESHOLD,
vvv$y,
weights = MY_WEIGHTS_vvv))
df_metrics
rm(temp_pred)
# save the df_metrics as .Rdata
save(df_metrics, pred_list, file = "df_metrics.Rdata")
# Importanza delle variabili
vimp = importance(random_forest_model)
PlotAndSave(my_plotting_function =  function() dotchart(vimp[order(vimp)],
pch = 16,
main = "Random Forest Variable Importance Permutation",
xlab = "error increase"),
my_path_plot = paste(FIGURES_FOLDER_RELATIVE_PATH,
"random_forest_importance_plot.jpeg",
collapse = ""))
# save metrics and model
file_name_random_forest = paste(MODELS_FOLDER_RELATIVE_PATH,
"random_forests",
".Rdata", collapse = "", sep = "")
save(random_forest_model, file = file_name_random_forest)
rm(random_forest_model)
gc()
library(ipred)
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
# Boosting ------------------------------
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
library(ada)
# massima profondità = 10
err_boost = rep(NA, 20)
iter_boost = 400
?rpart.control
# Stump
m_boost_stump = ada(x = sss[id_cb1, -y_index],
y = sss$y[id_cb1],
test.x = sss[-id_cb1, -y_index],
test.y = sss$y[-id_cb1],
iter = iter_boost,
control = rpart.control(maxdepth=1,
cp=-1,
minsplit=0,xval=0))
plot(m_boost_2, test = T)
plot(m_boost_stump, test = T)
PlotAndSave(my_plotting_function = function() plot(m_boost_stump,
test = T,
main = "Boosting"),
my_path_plot = paste(FIGURES_FOLDER_RELATIVE_PATH,
"random_forest_importance_plot.jpeg",
collapse = ""))
PlotAndSave(my_plotting_function = function() plot(m_boost_stump,
test = T),
my_path_plot = paste(FIGURES_FOLDER_RELATIVE_PATH,
"boosting_convergence.jpeg",
collapse = ""))
