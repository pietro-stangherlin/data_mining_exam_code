freq_threshold = temp_table_freq[24]
return(RaggruppaModalita(df, qual_vector_var_name, temp_table_freq,
freq_threshold, new_name))
}
char_var_names = colnames(dati[,-y_index])[which(unlist(lapply(dati[,-y_index], typeof)) == "character")]
for(name in char_var_names){
dati[,name] = GroupValuesQual(dati, name, "Altro")
}
str(dati)
# check
unique_vals_df = data.frame(nome = rep("", NCOL(dati)),
indice = rep(0, NCOL(dati)),
uniques = rep(0, NCOL(dati)))
unique_vals_df$nome = colnames(dati)
unique_vals_df$indice = as.numeric(1:NCOL(dati))
unique_vals_df$uniques = as.numeric(apply(dati, 2, function(col) length(unique(col))))
unique_vals_df
# eslcusione della y
unique_vals_df_no_y = unique_vals_df[-which(unique_vals_df$nome == "y"),]
unique_vals_df_no_y
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
# Riduzione quantitative in qualitative per poche modalità --------
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
# + qualitative che sono codificate numericamente
# indici delle esplicative con meno di min_modalità modalità
# da aumentare in base al problema
min_modalita = 2
index_min_modalita = unique_vals_df_no_y$indice[which(unique_vals_df_no_y$uniques <= min_modalita)]
index_min_modalita
# trasformo in fattore queste ultime
for(i in index_min_modalita){
dati[,i] = as.factor(dati[,i])
}
str(dati)
# +++++++++++++++++++++++++++++++++++++++++++++++++
# Nomi e indici di colonna delle variabili
# ++++++++++++++++++++++++++++++++++++++++++++++++++
# nomi delle esplicative qualitative e quantitative
# potrei dover effettuare questa operazione più volte
y_index = which(colnames(dati) == "y")
var_factor_index = which(sapply(dati, is.factor))
# se comprende l'indice della y  lo rimuovo
# da sistemare
if (y_index %in% var_factor_index){
var_factor_index = var_factor_index[-which(var_factor_index == y_index)]}
var_char_index = which(sapply(dati, is.character))
# se comprende l'indice della y  lo rimuovo
# da sistemare
if (y_index %in% var_char_index){
var_char_index = var_char_index[-which(var_char_index == y_index)]}
# comprende anche int
var_num_index = as.numeric(which(sapply(dati, is.numeric)))
# se comprende l'indice della y lo rimuovo
if (y_index %in% var_num_index){
var_num_index = var_num_index[-which(var_num_index == y_index)]}
# +++++++++++++++++++++++++++++++++++++++++++++++++
# Conversione character in factor
# ++++++++++++++++++++++++++++++++++++++++++++++++++
for(i in var_char_index){
dati[,i] = as.factor(dati[,i])
}
str(dati)
# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# Aggiorno indici qualitative e nomi qualitative e quantitative
# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
var_qual_index =  as.numeric(c(var_char_index, var_factor_index))
var_qual_names = var_names[var_qual_index]
var_num_names = var_names[var_num_index]
# check
var_qual_index
var_num_index
var_qual_names
var_num_names
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
# Analisi istrogramma quantitative -------------
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
# per ogni variabile esplicativa quantitativa
# disegna l'istrogramma della sua distribuzione empirica
# e quella del suo logaritmo (opportunamente traslata)
# @input: my_df (data.frame)
# @input var_index_subset (vector of int): indexes of quantitative variables subset
# output: plots of each quantitative variable histogram
DrawQuantHist = function(my_df,
var_index_subset = NULL,
my_breaks = 50){
# all variables
if(is.null(var_index_subset)){
var_index_subset = 1:NCOL(my_df)}
var_index_counter = 0
var_names_temp = colnames(my_df)
par(mfrow = c(1,2))
print("press (enter) to forward and 'b' to backward and q to quit")
while(var_index_counter < length(var_index_subset)){
input = readline("")
if((input == "q")){
var_index_counter = length(var_index_subset) - 1}
if((input != "b")){
var_index_counter = var_index_counter + 1}
if(input == "b"){
var_index_counter = var_index_counter - 1}
if(var_index_counter <= 0){
var_index_counter = 1}
# original scale
hist(my_df[,var_index_subset[var_index_counter]],
breaks = my_breaks,
main = var_names_temp[var_index_subset[var_index_counter]],
xlab = "values")
# log translated scale
temp_min = min(my_df[,var_index_subset[var_index_counter]])
if(temp_min > 0){
temp_min = 0}
hist(log(my_df[,var_index_subset[var_index_counter]] - temp_min + 1e-05 ),
breaks = my_breaks,
main = paste("log", var_names_temp[var_index_subset[var_index_counter]]),
xlab = "log values")
}
par(mfrow = c(1,1))
}
# Analisi istogrammi
# DrawQuantHist(dati, var_num_index)
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
# Scope ----------------------------------------
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
# funzione per creare le stringhe di interazione
# tra variabili della stessa tipologia
# (quantitativa - quantitativa e fattore - fattore)
# '@ input: array of strings
# '@ return string formula of interaction terms
# example :
# input = c("a", "b", "c")
# output = "a:b + a:c + b:c"
MakeSameInteractionsString = function(input_var_type_names){
# preliminary checks
if(length(input_var_type_names) == 0){
cat("Warning: input_var_type_names is of length 0, return empty string")
return("")
}
type_type_interactions_string = ""
for (i in 1:length(input_var_type_names)){
for (j in (i+1):length(input_var_type_names)){
if (!(is.na(input_var_type_names[i]) | is.na(input_var_type_names[j])) & (j != i))
type_type_interactions_string = paste(type_type_interactions_string,
" + ",
input_var_type_names[i],
":",
input_var_type_names[j])
}
}
# Remove the first " + " from the string
type_type_interactions_string = substring(type_type_interactions_string, 6)
return(type_type_interactions_string)
}
# stringhe intermedie
no_interaction_string = paste(var_names[-y_index], collapse = " + ")
qual_num_interactions_string = paste(outer(var_num_names,
var_qual_names,
FUN = function(x, y) paste(x, y, sep = ":")), collapse = " + ")
qual_qual_interactions_string = MakeSameInteractionsString(var_qual_names)
num_num_interactions_string = MakeSameInteractionsString(var_num_names)
# variabili quantitative al quadrato
num_vars_square_string = ""
if(length(var_num_names) != 0){
num_vars_square_string <- paste("I(",
var_num_names,
"^2)",
sep = "", collapse = " + ")}
# string terms vector: vector of string terms
# return formula object
MakeFormula = function(string_terms_vector, intercept_bool = TRUE){
base_formula = "y ~ "
# remove empty vector terms
string_terms_vector = string_terms_vector[which(string_terms_vector != "")]
if (intercept_bool == FALSE){
base_formula = paste(base_formula, " - 1 + ")
}
added_terms = paste(string_terms_vector, collapse = " + ")
return(as.formula(paste(base_formula, added_terms)))
}
# creazione delle formule
# per evitare errori dovuti a formule troppo lunghe
options(expressions = 50000)
formula_yes_interaction_yes_intercept <- MakeFormula(c(no_interaction_string,
num_vars_square_string,
qual_qual_interactions_string,
qual_num_interactions_string))
formula_yes_interaction_no_intercept <- MakeFormula(c(no_interaction_string,
num_vars_square_string,
qual_qual_interactions_string,
qual_num_interactions_string),
intercept_bool = FALSE)
formula_yes_interaction_yes_intercept
formula_yes_interaction_no_intercept
# formula senza interazioni
formula_no_interaction_yes_intercept = MakeFormula(no_interaction_string)
formula_no_interaction_no_intercept = MakeFormula(no_interaction_string, intercept_bool = FALSE)
formula_no_interaction_yes_intercept
formula_no_interaction_no_intercept
# /////////////////////////////////////////
# Backup data.frame + environment ---------
# ////////////////////////////////////////
save(dati,
y_index,
var_qual_index, var_qual_names,
var_num_index, var_num_names,
formula_no_interaction_no_intercept,
formula_no_interaction_yes_intercept,
formula_yes_interaction_no_intercept,
formula_yes_interaction_yes_intercept,
file = "result_preprocessing.Rdata")
# if necessary delete all
# rm(list = ls())
# in case of problems: load only useful objects
# load("result_preprocessing.Rdata")
# ///////////////////////////////////
# Save output on file ---------------
# //////////////////////////////////
# text.txt -------------
# # close previoulsy opened sink (if opened) -> I should make a control
# sink()
# initialize the output .txt file to regularly write on in case
# the software crashes
# open new sink
TEXT_OUTPUT_FILE_NAME = "text_output_models.txt"
# open sink
sink(TEXT_OUTPUT_FILE_NAME, append = TRUE, split = TRUE)
library(dplyr)
#////////////////////////////////////////////////////////////////////////////
# Costruzione metrica di valutazione e relativo dataframe -------------------
#////////////////////////////////////////////////////////////////////////////
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
# Quantitativa -------------------------------
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
source("loss_functions.R")
# °°°°°°°°°°°°°°°°°°°°°°° Warning: °°°°°°°°°°°°°°°°°°°°°°°°°°°°°°
# cambia la funzione di errore per il problema specifico
# in generale uso sia MAE che MSE
USED.Loss = function(y.pred, y.test, weights = 1){
return(c(MAE.Loss(y.pred, y.test, weights), MSE.Loss(y.pred, y.test, weights)))
}
# anche qua
df_metrics = data.frame(name = NA, MAE = NA, MSE = NA)
#' @param my_plotting_function (function): function with NO ARGUMENTS
#' outputting the desired plot
#' @param my_path_plot (char): path of the where the plot will be saved on disk
#' @param my_width (int): pixel width of saved plot
#' @param my_height (int): pixel height of saved plot
#' @param my_point_size (int): point size of saved plot
#' @param my_quality (int): quality of saved plot
#'
#' @description show plot determined by my_plotting_function and save it on disk
#'
#' @return None
PlotAndSave = function(my_plotting_function,
my_path_plot,
my_width = FIGURE_WIDTH,
my_height = FIGURE_HEIGHT,
my_point_size = FIGURE_POINT_SIZE,
my_quality = FIGURE_QUALITY){
# call to shown plot
my_plotting_function()
# plot saved on disk
jpeg(my_path_plot,
width = my_width, height = my_height,
pointsize = my_point_size, quality = my_quality)
# call to saved plot
my_plotting_function()
dev.off()
}
# /////////////////////////////////////////////////////////////////
#------------------------ Stima e Verifica ------------------------
# /////////////////////////////////////////////////////////////////
# Eventualmente modificare la proporzione
id_stima = sample(1:NROW(dati), 0.75 * NROW(dati))
sss = dati[id_stima,]
vvv = dati[-id_stima,]
# In caso di convalida nell'insieme di stima
id_cb1 = sample(1:NROW(sss), 0.8 * NROW(sss))
# rimozione dati originali
rm(dati)
gc()
# /////////////////////////////////////////////////////////////////
#------------------------ Analisi esplorative ---------------------
# /////////////////////////////////////////////////////////////////
# Analisi esplorativa sulla stima
# eventuali inflazioni di zeri
hist(sss$y,nclass = 100)
summary(sss$y)
# possiamo provare a trasformare la risposta
# ATTENZIONE se y è <= 0 -> trasforma in modo adeguato
hist(log(sss$y), nclass = 100)
# anche se le distribuzioni marginali non
# forniscono informazioni riguardo alle condizionate
# se per il problema in questione è sensato possiamo impiegare
# come nuova rispota il logaritmo della precedente y
# nota: in in questo modo la differenza dei logaritmi corrisponde
# al logaritmo del rapporto
# /////////////////////////////////////////////////////////////////
#------------------------ Modelli ---------------------------------
# /////////////////////////////////////////////////////////////////
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
# Media e Mediana --------------------
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
# aggiunta media e mediana della risposta sull'insieme di stima come possibili modelli
# (per valutare se modelli più complessi hanno senso)
df_metrics = Add_Test_Metric(df_metrics,
"sss mean",
USED.Loss(mean(sss$y), vvv$y))
df_metrics = Add_Test_Metric(df_metrics,
"sss median",
USED.Loss(median(sss$y), vvv$y))
df_metrics = na.omit(df_metrics)
df_metrics
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
# Modello lineare Forward --------------------
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
# AIC criterion is used for model selection
lm0 = lm(y ~ 1, data = sss)
# NO Interaction -----------
# °°°°°°°°°°°°°°°°°°°°°°°°°°°Warning: lento°°°°°°°°°°°°°°°°°°°°°°°°°°°°
lm_step_no_interaction = step(lm0, scope = formula_no_interaction_yes_intercept,
direction = "forward")
formula(lm_step_no_interaction)
# load(file_name_lm_step_no_interaction)
df_metrics = Add_Test_Metric(df_metrics,
"lm_step_no_interaction",
USED.Loss(predict(lm_step_no_interaction, newdata = vvv), vvv$y))
df_metrics
# save the model as .Rdata
# then remove it from main memory
file_name_lm_step_no_interaction = paste(MODELS_FOLDER_RELATIVE_PATH,
"lm_step_no_interaction",
".Rdata", collapse = "", sep = "")
save(lm_step_no_interaction, file = file_name_lm_step_no_interaction)
rm(lm_step_no_interaction)
gc()
# YES Interaction -----------
# computazionalmente costoso (probabilmente)
lm_step_yes_interaction = step(lm0, scope = formula_yes_interaction_yes_intercept,
direction = "forward")
formula(lm_step_yes_interaction)
df_metrics = Add_Test_Metric(df_metrics,
"lm_step_yes_interaction",
USED.Loss(predict(lm_step_yes_interaction, newdata = vvv), vvv$y))
# save the model as .Rdata
# then remove it from main memory
file_name_lm_step_yes_interaction = paste(MODELS_FOLDER_RELATIVE_PATH,
"lm_step_yes_interaction",
".Rdata", collapse = "", sep = "")
save(lm_step_yes_interaction, file = file_name_lm_step_yes_interaction)
rm(lm_step_yes_interaction)
rm(lm0)
gc()
# save the df_metrics as .Rdata
save(df_metrics, file = "df_metrics.Rdata")
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
# Ridge e Lasso ------------------------------
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
# Compromesso varianza - distorsione: convalida incrociata sull'insieme di stima
KFOLDS = 10
# valuta: se ci sono molte esplicative qualitative -> model.matrix con molti zeri
# library(Matrix)
X_mm_no_interaction_sss =  sparse.model.matrix(formula_no_interaction_no_intercept, data = sss)
X_mm_no_interaction_vvv =  sparse.model.matrix(formula_no_interaction_no_intercept, data = vvv)
# # oneroso
X_mm_yes_interaction_sss =  sparse.model.matrix(formula_yes_interaction_no_intercept, data = sss)
X_mm_yes_interaction_vvv =  sparse.model.matrix(formula_yes_interaction_no_intercept, data = vvv)
# default
# stima
# X_mm_no_interaction_sss = model.matrix(formula_no_interaction_no_intercept, data = sss)
# verifica
# X_mm_no_interaction_vvv = model.matrix(formula_no_interaction_no_intercept, data = vvv)
# Interazioni: stima
# X_mm_yes_interaction_sss = model.matrix(formula_yes_interaction_no_intercept,
#                                    data = sss)
# Interazioni verifica
#
# X_mm_yes_interaction_vvv = model.matrix(formula_yes_interaction_no_intercept,
#                                         data = vvv)
library(glmnet)
# criterion to choose the model: "1se" or "lmin"
cv_criterion = "1se"
# Ridge ------
# NO Interaction -----------
# Selezione tramite cv
ridge_cv_no_interaction = cv.glmnet(x = X_mm_no_interaction_sss, y = sss$y,
alpha = 0, nfols = KFOLDS,
lambda.min.ratio = 1e-07)
# define plotting function
temp_plotting_fun = function(){
plot(ridge_cv_no_interaction, main = "ridge no interaction")
}
PlotAndSave(temp_plotting_fun,
my_path_plot = paste(FIGURES_FOLDER_RELATIVE_PATH,
"ridge_no_int_plot.jpeg",
collapse = ""))
ridge_cv_no_interaction[[cv_criterion]]
ridge_no_interaction = glmnet(x = X_mm_no_interaction_sss, y = sss$y,
alpha = 0, nfols = KFOLDS, nfols = KFOLDS,
lambda = ridge_cv_no_interaction[[cv_criterion]])
# previsione ed errore
df_metrics = Add_Test_Metric(df_metrics,
"ridge_no_interaction",
USED.Loss(predict(ridge_no_interaction, newx = X_mm_no_interaction_vvv),vvv$y))
df_metrics
file_name_ridge_no_interaction = paste(MODELS_FOLDER_RELATIVE_PATH,
"ridge_no_interaction",
".Rdata", collapse = "", sep = "")
save(ridge_no_interaction, file = file_name_ridge_no_interaction)
# elimino dalla memoria l'oggetto ridge_cv
rm(ridge_cv_no_interaction)
rm(ridge_no_interaction)
gc()
# YES Interaction -----------
# # Selezione tramite cv
ridge_cv_yes_interaction = cv.glmnet(x = X_mm_yes_interaction_sss, y = sss$y,
alpha = 0, nfols = KFOLDS,
lambda.min.ratio = 1e-07)
# define plotting function
temp_plotting_fun = function(){
plot(ridge_cv_yes_interaction, main = "ridge yes interaction")
}
PlotAndSave(temp_plotting_fun,
my_path_plot = paste(FIGURES_FOLDER_RELATIVE_PATH,
"ridge_yes_int_plot.jpeg",
collapse = ""))
ridge_cv_yes_interaction[[cv_criterion]]
ridge_yes_interaction = glmnet(x = X_mm_yes_interaction_sss, y = sss$y,
alpha = 0, nfols = KFOLDS,
lambda = ridge_cv_yes_interaction[[cv_criterion]])
df_metrics = Add_Test_Metric(df_metrics,
"ridge_yes_interaction",
USED.Loss(predict(ridge_yes_interaction, newx = X_mm_yes_interaction_vvv),vvv$y))
file_name_ridge_yes_interaction = paste(MODELS_FOLDER_RELATIVE_PATH,
"ridge_yes_interaction",
".Rdata", collapse = "", sep = "")
save(ridge_yes_interaction, file = file_name_ridge_yes_interaction)
rm(ridge_cv_yes_interaction)
rm(ridge_yes_interaction)
gc()
# save the df_metrics as .Rdata
save(df_metrics, file = "df_metrics.Rdata")
# Lasso ------
# NO Interaction -----------
# Selezione tramite cv
lasso_cv_no_interaction = cv.glmnet(x = X_mm_no_interaction_sss, y = sss$y,
alpha = 0, nfols = KFOLDS,
lambda.min.ratio = 1e-07)
# define plotting function
temp_plotting_fun = function(){
plot(lasso_cv_no_interaction, main = "lasso no interaction")
}
PlotAndSave(temp_plotting_fun,
my_path_plot = paste(FIGURES_FOLDER_RELATIVE_PATH,
"lasso_no_int_plot.jpeg",
collapse = ""))
lasso_cv_no_interaction[[cv_criterion]]
lasso_no_interaction = glmnet(x = X_mm_no_interaction_sss, y = sss$y,
alpha = 0, nfols = KFOLDS, nfols = KFOLDS,
lambda = lasso_cv_no_interaction[[cv_criterion]])
# previsione ed errore
df_metrics = Add_Test_Metric(df_metrics,
"lasso_no_interaction",
USED.Loss(predict(lasso_no_interaction, newx = X_mm_no_interaction_vvv),vvv$y))
df_metrics
file_name_lasso_no_interaction = paste(MODELS_FOLDER_RELATIVE_PATH,
"lasso_no_interaction",
".Rdata", collapse = "", sep = "")
save(lasso_no_interaction, file = file_name_lasso_no_interaction)
# elimino dalla memoria l'oggetto lasso_cv
rm(lasso_cv_no_interaction)
rm(lasso_no_interaction)
gc()
# YES Interaction -----------
# # Selezione tramite cv
lasso_cv_yes_interaction = cv.glmnet(x = X_mm_yes_interaction_sss, y = sss$y,
alpha = 0, nfols = KFOLDS,
lambda.min.ratio = 1e-07)
# define plotting function
temp_plotting_fun = function(){
plot(lasso_cv_yes_interaction, main = "lasso yes interaction")
}
PlotAndSave(temp_plotting_fun,
my_path_plot = paste(FIGURES_FOLDER_RELATIVE_PATH,
"lasso_yes_int_plot.jpeg",
collapse = ""))
lasso_cv_yes_interaction[[cv_criterion]]
lasso_yes_interaction = glmnet(x = X_mm_yes_interaction_sss, y = sss$y,
alpha = 0, nfols = KFOLDS,
lambda = lasso_cv_yes_interaction[[cv_criterion]])
df_metrics = Add_Test_Metric(df_metrics,
"lasso_yes_interaction",
USED.Loss(predict(lasso_yes_interaction, newx = X_mm_yes_interaction_vvv),vvv$y))
file_name_lasso_yes_interaction = paste(MODELS_FOLDER_RELATIVE_PATH,
"lasso_yes_interaction",
".Rdata", collapse = "", sep = "")
save(lasso_yes_interaction, file = file_name_lasso_yes_interaction)
rm(lasso_cv_yes_interaction)
rm(lasso_yes_interaction)
gc()
# save the df_metrics as .Rdata
save(df_metrics, file = "df_metrics.Rdata")
lasso_cv_yes_interaction[[cv_criterion]]
# NO Interaction -----------
# Selezione tramite cv
lasso_cv_no_interaction = cv.glmnet(x = X_mm_no_interaction_sss, y = sss$y,
alpha = 0, nfols = KFOLDS,
lambda.min.ratio = 1e-07)
lasso_cv_no_interaction[[cv_criterion]]
lasso_cv_no_interaction
lasso_cv_no_interaction[["lambda.1se"]]
print(paste("ridge_cv_no_interaction ", cv_criterion, collapse = ""))
ridge_cv_no_interaction[[cv_criterion]]
