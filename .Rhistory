var_index_subset = 1:NCOL(my_df)}
var_index_counter = 0
var_names_temp = colnames(my_df)
par(mfrow = c(1,2))
print("press (enter) to forward and 'b' to backward and q to quit")
while(var_index_counter < length(var_index_subset)){
input = readline("")
if((input == "q")){
var_index_counter = length(var_index_subset) - 1}
if((input != "b")){
var_index_counter = var_index_counter + 1}
if(input == "b"){
var_index_counter = var_index_counter - 1}
if(var_index_counter <= 0){
var_index_counter = 1}
# original scale
hist(my_df[,var_index_subset[var_index_counter]],
breaks = my_breaks,
main = var_names_temp[var_index_subset[var_index_counter]],
xlab = "values")
# log translated scale
temp_min = min(my_df[,var_index_subset[var_index_counter]])
if(temp_min > 0){
temp_min = 0}
hist(log(my_df[,var_index_subset[var_index_counter]] - temp_min + 1e-05 ),
breaks = my_breaks,
main = paste("log", var_names_temp[var_index_subset[var_index_counter]]),
xlab = "log values")
}
par(mfrow = c(1,1))
}
# Analisi istogrammi
# DrawQuantHist(dati, var_num_index)
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
# Scope ----------------------------------------
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
# funzione per creare le stringhe di interazione
# tra variabili della stessa tipologia
# (quantitativa - quantitativa e fattore - fattore)
# '@ input: array of strings
# '@ return string formula of interaction terms
# example :
# input = c("a", "b", "c")
# output = "a:b + a:c + b:c"
MakeSameInteractionsString = function(input_var_type_names){
# preliminary checks
if(length(input_var_type_names) == 0){
cat("Warning: input_var_type_names is of length 0, return empty string")
return("")
}
type_type_interactions_string = ""
for (i in 1:length(input_var_type_names)){
for (j in (i+1):length(input_var_type_names)){
if (!(is.na(input_var_type_names[i]) | is.na(input_var_type_names[j])) & (j != i))
type_type_interactions_string = paste(type_type_interactions_string,
" + ",
input_var_type_names[i],
":",
input_var_type_names[j])
}
}
# Remove the first " + " from the string
type_type_interactions_string = substring(type_type_interactions_string, 6)
return(type_type_interactions_string)
}
# stringhe intermedie
no_interaction_string = paste(var_names[-y_index], collapse = " + ")
qual_num_interactions_string = paste(outer(var_num_names,
var_qual_names,
FUN = function(x, y) paste(x, y, sep = ":")), collapse = " + ")
qual_qual_interactions_string = MakeSameInteractionsString(var_qual_names)
num_num_interactions_string = MakeSameInteractionsString(var_num_names)
# variabili quantitative al quadrato
num_vars_square_string = ""
if(length(var_num_names) != 0){
num_vars_square_string <- paste("I(",
var_num_names,
"^2)",
sep = "", collapse = " + ")}
# string terms vector: vector of string terms
# return formula object
MakeFormula = function(string_terms_vector, intercept_bool = TRUE){
base_formula = "y ~ "
# remove empty vector terms
string_terms_vector = string_terms_vector[which(string_terms_vector != "")]
if (intercept_bool == FALSE){
base_formula = paste(base_formula, " - 1 + ")
}
added_terms = paste(string_terms_vector, collapse = " + ")
return(as.formula(paste(base_formula, added_terms)))
}
# creazione delle formule
# per evitare errori dovuti a formule troppo lunghe
options(expressions = 50000)
formula_yes_interaction_yes_intercept <- MakeFormula(c(no_interaction_string,
num_vars_square_string,
qual_qual_interactions_string,
qual_num_interactions_string))
formula_yes_interaction_no_intercept <- MakeFormula(c(no_interaction_string,
num_vars_square_string,
qual_qual_interactions_string,
qual_num_interactions_string),
intercept_bool = FALSE)
formula_yes_interaction_yes_intercept
formula_yes_interaction_no_intercept
# formula senza interazioni
formula_no_interaction_yes_intercept = MakeFormula(no_interaction_string)
formula_no_interaction_no_intercept = MakeFormula(no_interaction_string, intercept_bool = FALSE)
formula_no_interaction_yes_intercept
formula_no_interaction_no_intercept
# /////////////////////////////////////////
# Backup data.frame + environment ---------
# ////////////////////////////////////////
save(dati,
y_index,
var_qual_index, var_qual_names,
var_num_index, var_num_names,
formula_no_interaction_no_intercept,
formula_no_interaction_yes_intercept,
formula_yes_interaction_no_intercept,
formula_yes_interaction_yes_intercept,
FIGURES_FOLDER_RELATIVE_PATH,
MODELS_FOLDER_RELATIVE_PATH,
file = "result_preprocessing.Rdata")
# if necessary delete all
# rm(list = ls())
# in case of problems: load only useful objects
# load("result_preprocessing.Rdata")
# ///////////////////////////////////
# Save output on file ---------------
# //////////////////////////////////
# text.txt -------------
# # close previoulsy opened sink (if opened) -> I should make a control
# sink()
# initialize the output .txt file to regularly write on in case
# the software crashes
# open new sink
TEXT_OUTPUT_FILE_NAME = "text_output_models.txt"
# open sink
sink(TEXT_OUTPUT_FILE_NAME, append = TRUE, split = TRUE)
# data wrangling
library(dplyr)
# parallel computing
library(snowfall)
# number of cores
N_CORES = parallel::detectCores()
load("result_preprocessing.Rdata")
#////////////////////////////////////////////////////////////////////////////
# Metrics and data.frame --------------------------------------------------
#////////////////////////////////////////////////////////////////////////////
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
# Quantitative response ---------------------
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
source("loss_functions.R")
# °°°°°°°°°°°°°°°°°°°°°°° Warning: °°°°°°°°°°°°°°°°°°°°°°°°°°°°°°
USED.Metrics = function(y.pred, y.test, weights = 1){
return(MissErr(y.pred, y.test, weights))
}
# anche qua
df_metrics = data.frame(name = NA,
missclass = NA)
METRICS_NAMES = colnames(df_metrics[,-1])
N_METRICS = length(METRICS_NAMES)
# names used to extract the metric added to df_metrics
# change based on the specific problem
METRIC_VALUES_NAME = "metric_values"
METRIC_CHOSEN_NAME = "missclass"
# names used for accessing list CV matrix (actual metrics and metrics se)
LIST_METRICS_ACCESS_NAME = "metrics"
LIST_SD_ACCESS_NAME = "se"
# metrics names + USED.Loss
# WARNING: the order should be same as in df_metrics
MY_USED_METRICS = c("USED.Metrics", "MissErr")
# /////////////////////////////////////////////////////////////////
#------------------------ Train & Test ------------------------
# /////////////////////////////////////////////////////////////////
# eventually change the proportion
id_stima = sample(1:NROW(dati), 0.75 * NROW(dati))
sss = dati[id_stima,]
vvv = dati[-id_stima,]
# lista dei predittori (se stima - verifica)
# per LIFT e ROC
pred_list = list()
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
# Parameter tuning: Train & Test on Train subset  --------------
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
id_cb1 = sample(1:NROW(sss), 0.8 * NROW(sss))
# delete original data.frame from main memory
rm(dati)
gc()
sss$y = factor(sss$y)
vvv$y = factor(vvv$y)
# ///////////////////////////////////
# Weights ---------------
# //////////////////////////////////
# weights used for each metric function
# default 1
MY_WEIGHTS_sss = rep(1, NROW(sss))
MY_WEIGHTS_vvv = rep(1, NROW(vvv))
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
# Parameter tuning: cross validation on train: building cv folds  -------------------
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
K_FOLDS = 10
NROW_sss = NROW(sss)
SHUFFLED_ID = sample(1:NROW_sss, NROW_sss)
# NOTE: if the row number of sss is not a multiple of K_FOLDS
# the last fold repeats some ids from the first
# this is fixed in the code below
id_matrix_cv = matrix(SHUFFLED_ID, ncol = K_FOLDS)
# conversion of matrix in list of elements: each element contains a subset of ids
ID_CV_LIST = list()
for(j in 1:ncol(id_matrix_cv)){
ID_CV_LIST[[j]] = id_matrix_cv[,j]
}
rm(id_matrix_cv)
gc()
# repeated ids fixing
integer_division_cv = NROW_sss %/% K_FOLDS
modulo_cv = NROW_sss %% K_FOLDS
if(modulo_cv != 0){
ID_CV_LIST[[K_FOLDS]] = ID_CV_LIST[[K_FOLDS]][1:integer_division_cv]
}
source("cv_functions.R")
# FALSE = traditional CV on all folds
# TRUE -> use only first fold to test and all other to fit
USE_ONLY_FIRST_FOLD = FALSE
# /////////////////////////////////////////////////////////////////
#------------------------ Analisi esplorative ---------------------
# /////////////////////////////////////////////////////////////////
# Analisi esplorativa sulla stima
# eventuali inflazioni di zeri
# valutiamo se è sbilanciata
# ed eventualmente se è ragionevole cambiare la solita soglia a 0.5
table(sss$y)
# /////////////////////////////////////////////////////////////////
#------------------------ Modelli ---------------------------------
# /////////////////////////////////////////////////////////////////
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
# Creazione indicatrice --------------------
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
#carico la libreria nnet in cui c'e' il comando class.ind che crea le
# variabili indicatrici per le modalità della risposta
library(nnet)
Y_sss = class.ind(sss$y)
Y_LEVELS_SORTED = colnames(Y_sss)
# models list: where each model is stored
lm_no_int_models_list = list()
for(col in 1:NCOL(Y_sss)){
lm0 = lm(Y_sss[,i] ~ 1, data = sss[,-y_index])
lm_models_list[[i]] = step(lm0,
scope = formula_no_interaction_yes_intercept,
direction = "forward")
}
for(col in 1:NCOL(Y_sss)){
lm0 = lm(Y_sss[,col] ~ 1, data = sss[,-y_index])
lm_models_list[[col]] = step(lm0,
scope = formula_no_interaction_yes_intercept,
direction = "forward")
}
# models list: where each model is stored
lm_no_int_models_list = list()
for(col in 1:NCOL(Y_sss)){
lm0 = lm(Y_sss[,col] ~ 1, data = sss[,-y_index])
lm_no_int_models_list[[col]] = step(lm0,
scope = formula_no_interaction_yes_intercept,
direction = "forward")
}
for(col in 1:NCOL(Y_sss)){
lm0 = lm(Y_sss[id_cb1,col] ~ 1, data = sss[id_cb1,-y_index])
lm_no_int_models_list[[col]] = step(lm0,
scope = formula_no_interaction_yes_intercept,
direction = "forward")
}
# models list: where each model is stored
lm_no_int_models_list = list()
for(col in 1:NCOL(Y_sss)){
lm0 = lm(Y_sss[,col] ~ 1, data = sss[,-y_index])
lm_no_int_models_list[[col]] = step(lm0,
scope = formula_no_interaction_yes_intercept,
direction = "forward")
}
lapply(lm_no_int_models_list, function(el) predict(el, newdata = vvv))
head(lapply(lm_no_int_models_list, function(el) predict(el, newdata = vvv)))
t = lapply(lm_no_int_models_list, function(el) predict(el, newdata = vvv))
str(t)
temp_pred_scores = lapply(lm_no_int_models_list, function(el) predict(el, newdata = vvv))
rm(t)
temp_pred_scores = lapply(lm_no_int_models_list, function(el) predict(el, newdata = vvv))
temp_pred_scores = matrix(unlist(temp_pred_scores), ncol = NCOL(Y_sss), byrow = T)
temp_pred_scores
dim(temp_pred_scores)
temp_pred_scores = lapply(lm_no_int_models_list, function(el) predict(el, newdata = vvv))
temp_pred_scores[[2]] == matrix(unlist(temp_pred_scores), ncol = NCOL(Y_sss), byrow = T)[,2]
temp_pred_scores[[2]] == matrix(unlist(temp_pred_scores), ncol = NCOL(Y_sss), byrow = F)[,2]
temp_pred_scores = lapply(lm_no_int_models_list, function(el) predict(el, newdata = vvv))
temp_pred_scores = matrix(unlist(temp_pred_scores), ncol = NCOL(Y_sss))
temp_pred = Y_LEVELS_SORTED[apply(temp_pred_scores, 1, which.max)]
temp_pred
file_name_lm_no_int_models_list = paste(MODELS_FOLDER_RELATIVE_PATH,
"lm_no_int_models_list",
".Rdata", collapse = "", sep = "")
save(lm_no_int_models_list, file = file_namelm_no_int_models_list)
save(lm_no_int_models_list, file = file_name_lm_no_int_models_list)
df_metrics = Add_Test_Metric(df_metrics,
"lm_no_int_models_list",
USED.Metrics(temp_pred,
vvv$y,
MY_WEIGHTS_vvv))
df_metrics = na.omit(df_metrics)
df_metrics
# Yes Interaction ----------------
# models list: where each model is stored
lm_yes_int_models_list = list()
for(col in 1:NCOL(Y_sss)){
lm0 = lm(Y_sss[,col] ~ 1, data = sss[,-y_index])
lm_yes_int_models_list[[col]] = step(lm0,
scope = formula_yes_interaction_yes_intercept,
direction = "forward")
}
temp_pred_scores = lapply(lm_no_yes_models_list, function(el) predict(el, newdata = vvv))
temp_pred_scores = lapply(lm_yes_yes_models_list, function(el) predict(el, newdata = vvv))
# Yes Interaction ----------------
# models list: where each model is stored
lm_yes_int_models_list = list()
for(col in 1:NCOL(Y_sss)){
lm0 = lm(Y_sss[,col] ~ 1, data = sss[,-y_index])
lm_yes_int_models_list[[col]] = step(lm0,
scope = formula_yes_interaction_yes_intercept,
direction = "forward")
}
temp_pred_scores = lapply(lm_yes_int_models_list, function(el) predict(el, newdata = vvv))
temp_pred_scores = matrix(unlist(temp_pred_scores), ncol = NCOL(Y_sss))
temp_pred = Y_LEVELS_SORTED[apply(temp_pred_scores, 1, which.max)]
file_name_lm_yes_int_models_list = paste(MODELS_FOLDER_RELATIVE_PATH,
"lm_yes_int_models_list",
".Rdata", collapse = "", sep = "")
save(lm_no_yes_models_list, file = file_name_lm_yes_int_models_list)
df_metrics = Add_Test_Metric(df_metrics,
"lm_no_yes_models_list",
USED.Metrics(temp_pred,
vvv$y,
MY_WEIGHTS_vvv))
save(lm_yes_int_models_list, file = file_name_lm_yes_int_models_list)
df_metrics = Add_Test_Metric(df_metrics,
"lm_no_yes_models_list",
USED.Metrics(temp_pred,
vvv$y,
MY_WEIGHTS_vvv))
df_metrics
rounded_df = cbind(df_metrics[,1],
apply(df_metrics[,2:NCOL(df_metrics)], 2, function(col) round(as.numeric(col), 2)))
df_metrics
df_metrics
library(VGAM)
?vgam
# models list: where each model is stored
gam_models_list = list()
for(col in 1:NCOL(Y_sss)){
gam0 = gam(Y_sss[,col] ~ 1, data =sss[,-y_index])
# gam recognizes factor predictors
my_gam_scope = gam.scope(sss[,-y_index], arg = c("df=2", "df=3", "df=4", "df=5", "df=6"))
gam_models_list[[col]] = step.Gam(gam0, scope = my_gam_scope)
}
library(gam)
library(gam)
# models list: where each model is stored
gam_models_list = list()
# gam recognizes factor predictors
my_gam_scope = gam.scope(sss[,-y_index], arg = c("df=2", "df=3", "df=4", "df=5", "df=6"))
for(col in 1:NCOL(Y_sss)){
gam0 = gam(Y_sss[,col] ~ 1, data =sss[,-y_index])
gam_models_list[[col]] = step.Gam(gam0, scope = my_gam_scope)
}
temp_pred_scores = lapply(gam_models_list, function(el) predict(el, newdata = vvv))
temp_pred_scores = matrix(unlist(temp_pred_scores), ncol = NCOL(Y_sss))
temp_pred = Y_LEVELS_SORTED[apply(temp_pred_scores, 1, which.max)]
file_name_gam_models_list = paste(MODELS_FOLDER_RELATIVE_PATH,
"gam_models_list",
".Rdata", collapse = "", sep = "")
save(gam_models_list, file = file_name_gam_models_list)
df_metrics = Add_Test_Metric(df_metrics,
"gam_models_list",
USED.Metrics(temp_pred,
vvv$y,
MY_WEIGHTS_vvv))
df_metrics
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
# Multilogit --------------------
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
library(VGAM)
?vglm
vglm0 = vglm(Y_sss ~ 1, data = sss, family = "multilogit")
vglm0 = vglm(Y_sss ~ 1,
data = sss,
multinomial)
vglm0 = vglm(Y_sss ~ 1,
data = sss,
multinomial)
vglm_step = step4vglm(vglm0,
scope = formula_no_interaction_yes_intercept,
direction = "forward")
setwd("C:/Users/pietr/OneDrive - Università degli Studi di Padova/UNI/Corsi/Magistrale/Primo Anno/Secondo semestre/Data Mining/Exam used code templates/Exam Preparation Code")
# data wrangling
library(dplyr)
# parallel computing
library(snowfall)
# number of cores
N_CORES = parallel::detectCores()
load("result_preprocessing.Rdata")
source("loss_functions.R")
# °°°°°°°°°°°°°°°°°°°°°°° Warning: °°°°°°°°°°°°°°°°°°°°°°°°°°°°°°
USED.Metrics = function(y.pred, y.test, weights = 1){
return(MissErr(y.pred, y.test, weights))
}
# anche qua
df_metrics = data.frame(name = NA,
missclass = NA)
METRICS_NAMES = colnames(df_metrics[,-1])
N_METRICS = length(METRICS_NAMES)
# names used to extract the metric added to df_metrics
# change based on the specific problem
METRIC_VALUES_NAME = "metric_values"
METRIC_CHOSEN_NAME = "missclass"
# names used for accessing list CV matrix (actual metrics and metrics se)
LIST_METRICS_ACCESS_NAME = "metrics"
LIST_SD_ACCESS_NAME = "se"
# metrics names + USED.Loss
# WARNING: the order should be same as in df_metrics
MY_USED_METRICS = c("USED.Metrics", "MissErr")
# eventually change the proportion
id_stima = sample(1:NROW(dati), 0.75 * NROW(dati))
sss = dati[id_stima,]
vvv = dati[-id_stima,]
# lista dei predittori (se stima - verifica)
# per LIFT e ROC
pred_list = list()
id_cb1 = sample(1:NROW(sss), 0.8 * NROW(sss))
# delete original data.frame from main memory
rm(dati)
gc()
sss$y = factor(sss$y)
vvv$y = factor(vvv$y)
# weights used for each metric function
# default 1
MY_WEIGHTS_sss = rep(1, NROW(sss))
MY_WEIGHTS_vvv = rep(1, NROW(vvv))
K_FOLDS = 10
NROW_sss = NROW(sss)
SHUFFLED_ID = sample(1:NROW_sss, NROW_sss)
# NOTE: if the row number of sss is not a multiple of K_FOLDS
# the last fold repeats some ids from the first
# this is fixed in the code below
id_matrix_cv = matrix(SHUFFLED_ID, ncol = K_FOLDS)
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
# Multilogit --------------------
# @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
library(VGAM)
vglm0 = vglm(Y_sss ~ 1,
data = sss,
multinomial)
#carico la libreria nnet in cui c'e' il comando class.ind che crea le
# variabili indicatrici per le modalità della risposta
library(nnet)
Y_sss = class.ind(sss$y)
Y_LEVELS_SORTED = colnames(Y_sss)
vglm0 = vglm(Y_sss ~ 1,
data = sss,
multinomial)
vglm_step = step4vglm(vglm0,
scope = formula_no_interaction_yes_intercept,
direction = "forward")
vglm0 = vglm(Y_sss ~ 1,
data = sss,
multinomial,
etastart = 1)
vglm0 = vglm(Y_sss ~ 1,
data = sss[,-y_index],
multinomial)
vglm_step = step4vglm(vglm0,
scope = formula_no_interaction_yes_intercept,
direction = "forward")
Y_sss = class.ind(iris$Species)
sss = iris
vglm0 = vglm(Y_sss ~ 1,
data = sss[,-"Species"],
multinomial)
colnames(iris)
vglm0 = vglm(Y_sss ~ 1,
data = sss[,-5],
multinomial)
vglm_step = step4vglm(vglm0,
scope = formula_no_interaction_yes_intercept,
direction = "forward")
vglm_step = step4vglm(vglm0,
scope = "y ~ .",
direction = "forward")
formula(lm(Species ~., data = iris))
vglm_step = step4vglm(vglm0,
scope = as.formula(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width),
direction = "forward")
predict(vglm_step)
predict(vglm_step, type = "class")
predict(vglm_step, type = "terms")
predict(vglm_step, type = "response")
predict(vglm_step, type = "link")
Y_LEVELS_SORTED = colnames(Y_sss)
temp_pred = Y_LEVELS_SORTED[apply(predict(vglm_step, type = "response"), 1, which.max)]
temp_pred
temp_pred = Y_LEVELS_SORTED[apply(predict(vglm_step, type = "response", newdata = vvv), 1, which.max)]
vvv = iris[1:20, -5]
temp_pred = Y_LEVELS_SORTED[apply(predict(vglm_step, type = "response", newdata = vvv), 1, which.max)]
temp_pred
