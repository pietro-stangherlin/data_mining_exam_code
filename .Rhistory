METRIC_CHOSEN_NAME
ridge_no_int_best_summary[[METRIC_CHOSEN_NAME]][["best_param_value"]]
df_metrics = Add_Test_Metric(df_metrics,
"ridge_no_interaction",
USED.Metrics(predict(ridge_no_interaction, newx = X_mm_no_interaction_vvv),
vvv$y,
weights = MY_WEIGHTS_vvv))
df_metrics
df_metrics
METRIC_CHOSEN_NAME = "f_score"
ridge_no_interaction = glmnet(x = X_mm_no_interaction_sss,
y = sss$y,
alpha = 0,
lambda = ridge_no_int_best_summary[[METRIC_CHOSEN_NAME]][["best_param_value"]])
df_metrics = Add_Test_Metric(df_metrics,
"ridge_no_interaction",
USED.Metrics(predict(ridge_no_interaction, newx = X_mm_no_interaction_vvv),
vvv$y,
weights = MY_WEIGHTS_vvv))
df_metrics
ridge_no_int_best_summary[[METRIC_CHOSEN_NAME]][["best_param_value"]]
warnings()
df_metrics = Add_Test_Metric(df_metrics,
"ridge_no_interaction",
USED.Metrics(predict(ridge_no_interaction, newx = X_mm_no_interaction_vvv) > MY_THRESHOLD,
vvv$y,
weights = MY_WEIGHTS_vvv))
df_metrics
CvMetricBest = function(my_param_values,
my_metric_matrix,
my_se_matrix = 0,
my_metric_names,
my_one_se_best = TRUE,
my_higher_more_complex = TRUE,
indexes_metric_max = 0){
# this code is sub-optimal, someday I'll change it
# compute standard deviations matrix lower and upper
se_lower = my_metric_matrix - my_se_matrix
se_upper = my_metric_matrix + my_se_matrix
# BEST PARAM VALUES section
n_col_metric_matrix = NCOL(my_metric_matrix)
best_params = rep(NA, n_col_metric_matrix)
names(best_params) = my_metric_names
# Check metrics min and max best
if(indexes_metric_max == 0){
indexes_best_params = apply(as.matrix(my_metric_matrix, 2, which.min))
}
if(indexes_metric_max > 0){
indexes_best_params = c(apply(as.matrix(my_metric_matrix[,-indexes_metric_max], 2, which.min)),
apply(as.matrix(my_metric_matrix[,indexes_metric_max]), 2, which.max))
}
if(my_one_se_best == TRUE){
# non efficient procedure, but we assume the parameter space is small
# find all indexes for which the best error is inside the 1se band
for(i in 1:length(indexes_best_params)){
# more readable code
temp_best_metric = my_metric_matrix[indexes_best_params[i], i]
# parameter indexes for which the metric is inside the 1se band of best param metric
temp_param_indexes = which(my_param_values %in% my_param_values[which(temp_best_metric > se_lower[,i] &
temp_best_metric < se_upper[,i])])
if(my_higher_more_complex == TRUE){
indexes_best_params[i]= temp_param_indexes[which.min(my_param_values[temp_param_indexes])]
}
if(my_higher_more_complex == FALSE){
indexes_best_params[i]= temp_param_indexes[which.max(my_param_values[temp_param_indexes])]
}
}
}
best_params = my_param_values[indexes_best_params]
# return indexes and best param values
returned_list = list()
# cycle over all metrics
for (i in 1:n_col_metric_matrix){
# add index
returned_list[[my_metric_names[i]]][["best_param_index"]] = indexes_best_params[i]
# add param value
returned_list[[my_metric_names[i]]][["best_param_value"]] = best_params[i]
# add all metrics relative to that row (best param index row)
returned_list[[my_metric_names[i]]][["metric_values"]] = my_metric_matrix[indexes_best_params[i],]
}
return(returned_list)
}
df_metrics
table(vvv$y)
table(predict(ridge_no_interaction, newx = X_mm_no_interaction_vvv) > MY_THRESHOLD,)
table(predict(ridge_no_interaction, newx = X_mm_no_interaction_vvv) > MY_THRESHOLD)
sum(vvv$y == predict(ridge_no_interaction, newx = X_mm_no_interaction_vvv) > MY_THRESHOLD)
sum(vvv$y == (predict(ridge_no_interaction, newx = X_mm_no_interaction_vvv) > MY_THRESHOLD))
sum(vvv$y != (predict(ridge_no_interaction, newx = X_mm_no_interaction_vvv) > MY_THRESHOLD))
sum(vvv$y != (predict(ridge_no_interaction, newx = X_mm_no_interaction_vvv) > MY_THRESHOLD)) / NROW(vvv)
head(MY_WEIGHTS_vvv)
# weights: solo per tasso di errata classificazione
tabella.sommario = function(previsti, osservati,
print_bool = FALSE,
weights = 1){
# inizializza: per evitare casi in cui la tabella non è 2x2
n <-  matrix(0, nrow = 2, ncol = 2)
# for (i in 1:length(previsti)){
#   if(previsti[i] == osservati[i]){
#     # 0 == 0 case
#     if (previsti[i] == 0){
#       n[1,1] = n[1,1] + 1
#     }
#     # 1 == 1
#     else{
#       n[2,2] = n[2,2] + 1}
#   }
#
#   else{
#     # 0 != 1
#     if (previsti[i] == 0){
#       n[1,2] = n[1,2] + 1
#     }
#     # 1 != 0
#     else{
#       n[2,1] = n[2,1] + 1
#     }
#
#   }
# }
n = table(previsti, osservati)
err.tot <- sum((previsti != osservati) * weights) / sum(length(previsti) * weights)
zeros.observed = sum(n[1,1] + n[2,1])
ones.observed = sum(n[1,2] + n[2,2])
fn <- n[1,2]/ones.observed
fp <- n[2,1]/zeros.observed
tp = 1 - fn
tn = 1 - fp
f.score = 2*tp / (2*tp + fp + fn)
if(print_bool == TRUE){
print(n)
print(c("err tot", "fp", "fn", "f.score"))
print(c(err.tot, fp, fn, f.score))}
return(c(err.tot, fp, fn, f.score))
}
ridge_no_interaction_metrics = ManualCvGlmnet(my_id_list_cv = ID_CV_LIST,
my_metric_names = METRICS_NAMES,
my_x = X_mm_no_interaction_sss,
my_y = sss$y,
my_alpha = 0,
my_lambda_vals = lambda_vals,
my_weights = MY_WEIGHTS_sss,
use_only_first_fold = USE_ONLY_FIRST_FOLD,
is_classification = TRUE,
my_threshold = MY_THRESHOLD)
table(vvv$y,(predict(ridge_no_interaction, newx = X_mm_no_interaction_vvv) > MY_THRESHOLD))
# weights: solo per tasso di errata classificazione
tabella.sommario = function(previsti, osservati,
print_bool = FALSE,
weights = 1){
# inizializza: per evitare casi in cui la tabella non è 2x2
n <-  matrix(0, nrow = 2, ncol = 2)
# for (i in 1:length(previsti)){
#   if(previsti[i] == osservati[i]){
#     # 0 == 0 case
#     if (previsti[i] == 0){
#       n[1,1] = n[1,1] + 1
#     }
#     # 1 == 1
#     else{
#       n[2,2] = n[2,2] + 1}
#   }
#
#   else{
#     # 0 != 1
#     if (previsti[i] == 0){
#       n[1,2] = n[1,2] + 1
#     }
#     # 1 != 0
#     else{
#       n[2,1] = n[2,1] + 1
#     }
#
#   }
# }
n = table(previsti, oss)
err.tot <- sum((previsti != osservati) * weights) / sum(rep(1, length(previsti)) * weights)
zeros.observed = sum(n[1,1] + n[2,1])
ones.observed = sum(n[1,2] + n[2,2])
fn <- n[1,2]/ones.observed
fp <- n[2,1]/zeros.observed
tp = 1 - fn
tn = 1 - fp
f.score = 2*tp / (2*tp + fp + fn)
if(print_bool == TRUE){
print(n)
print(c("err tot", "fp", "fn", "f.score"))
print(c(err.tot, fp, fn, f.score))}
return(c(err.tot, fp, fn, f.score))
}
table(vvv$y,(predict(ridge_no_interaction, newx = X_mm_no_interaction_vvv) > MY_THRESHOLD))
tabella.sommario(vvv$y,(predict(ridge_no_interaction, newx = X_mm_no_interaction_vvv) > MY_THRESHOLD))
# weights: solo per tasso di errata classificazione
tabella.sommario = function(previsti, osservati,
print_bool = FALSE,
weights = 1){
# inizializza: per evitare casi in cui la tabella non è 2x2
n <-  matrix(0, nrow = 2, ncol = 2)
# for (i in 1:length(previsti)){
#   if(previsti[i] == osservati[i]){
#     # 0 == 0 case
#     if (previsti[i] == 0){
#       n[1,1] = n[1,1] + 1
#     }
#     # 1 == 1
#     else{
#       n[2,2] = n[2,2] + 1}
#   }
#
#   else{
#     # 0 != 1
#     if (previsti[i] == 0){
#       n[1,2] = n[1,2] + 1
#     }
#     # 1 != 0
#     else{
#       n[2,1] = n[2,1] + 1
#     }
#
#   }
# }
n = table(previsti, osservati)
err.tot <- sum((previsti != osservati) * weights) / sum(rep(1, length(previsti)) * weights)
zeros.observed = sum(n[1,1] + n[2,1])
ones.observed = sum(n[1,2] + n[2,2])
fn <- n[1,2]/ones.observed
fp <- n[2,1]/zeros.observed
tp = 1 - fn
tn = 1 - fp
f.score = 2*tp / (2*tp + fp + fn)
if(print_bool == TRUE){
print(n)
print(c("err tot", "fp", "fn", "f.score"))
print(c(err.tot, fp, fn, f.score))}
return(c(err.tot, fp, fn, f.score))
}
tabella.sommario(vvv$y,(predict(ridge_no_interaction, newx = X_mm_no_interaction_vvv) > MY_THRESHOLD))
# weights: solo per tasso di errata classificazione
tabella.sommario = function(previsti, osservati,
print_bool = FALSE,
weights = 1){
# inizializza: per evitare casi in cui la tabella non è 2x2
n <-  matrix(0, nrow = 2, ncol = 2)
for (i in 1:length(previsti)){
if(previsti[i] == osservati[i]){
# 0 == 0 case
if (previsti[i] == 0){
n[1,1] = n[1,1] + 1
}
# 1 == 1
else{
n[2,2] = n[2,2] + 1}
}
else{
# 0 != 1
if (previsti[i] == 0){
n[1,2] = n[1,2] + 1
}
# 1 != 0
else{
n[2,1] = n[2,1] + 1
}
}
}
# n = table(previsti, osservati)
err.tot <- sum((previsti != osservati) * weights) / sum(rep(1, length(previsti)) * weights)
zeros.observed = sum(n[1,1] + n[2,1])
ones.observed = sum(n[1,2] + n[2,2])
fn <- n[1,2]/ones.observed
fp <- n[2,1]/zeros.observed
tp = 1 - fn
tn = 1 - fp
f.score = 2*tp / (2*tp + fp + fn)
if(print_bool == TRUE){
print(n)
print(c("err tot", "fp", "fn", "f.score"))
print(c(err.tot, fp, fn, f.score))}
return(c(err.tot, fp, fn, f.score))
}
tabella.sommario(vvv$y,(predict(ridge_no_interaction, newx = X_mm_no_interaction_vvv) > MY_THRESHOLD))
0 == FALSE
ridge_no_interaction_metrics = ManualCvGlmnet(my_id_list_cv = ID_CV_LIST,
my_metric_names = METRICS_NAMES,
my_x = X_mm_no_interaction_sss,
my_y = sss$y,
my_alpha = 0,
my_lambda_vals = lambda_vals,
my_weights = MY_WEIGHTS_sss,
use_only_first_fold = USE_ONLY_FIRST_FOLD,
is_classification = TRUE,
my_threshold = MY_THRESHOLD)
ridge_no_int_best_summary = CvMetricBest(my_param_values = lambda_vals,
my_metric_matrix = ridge_no_interaction_metrics[["metrics"]],
my_one_se_best = TRUE,
my_higher_more_complex = FALSE,
my_se_matrix = ridge_no_interaction_metrics[["se"]],
my_metric_names = METRICS_NAMES,
indexes_metric_max = 4) # f_score: higher better
CvMetricBest = function(my_param_values,
my_metric_matrix,
my_se_matrix = 0,
my_metric_names,
my_one_se_best = TRUE,
my_higher_more_complex = TRUE,
indexes_metric_max = 0){
# this code is sub-optimal, someday I'll change it
# compute standard deviations matrix lower and upper
se_lower = my_metric_matrix - my_se_matrix
se_upper = my_metric_matrix + my_se_matrix
# BEST PARAM VALUES section
n_col_metric_matrix = NCOL(my_metric_matrix)
best_params = rep(NA, n_col_metric_matrix)
names(best_params) = my_metric_names
# Check metrics min and max best
if(indexes_metric_max == 0){
indexes_best_params = apply(as.matrix(my_metric_matrix, 2, which.min))
}
if(indexes_metric_max > 0){
indexes_best_params = c(apply(as.matrix(my_metric_matrix[,-indexes_metric_max], 2, which.min)),
apply(as.matrix(my_metric_matrix[,indexes_metric_max]), 2, which.max))
}
if(my_one_se_best == TRUE){
# non efficient procedure, but we assume the parameter space is small
# find all indexes for which the best error is inside the 1se band
for(i in 1:length(indexes_best_params)){
# more readable code
temp_best_metric = my_metric_matrix[indexes_best_params[i], i]
# parameter indexes for which the metric is inside the 1se band of best param metric
temp_param_indexes = which(my_param_values %in% my_param_values[which(temp_best_metric > se_lower[,i] &
temp_best_metric < se_upper[,i])])
if(my_higher_more_complex == TRUE){
indexes_best_params[i]= temp_param_indexes[which.min(my_param_values[temp_param_indexes])]
}
if(my_higher_more_complex == FALSE){
indexes_best_params[i]= temp_param_indexes[which.max(my_param_values[temp_param_indexes])]
}
}
}
best_params = my_param_values[indexes_best_params]
# return indexes and best param values
returned_list = list()
# cycle over all metrics
for (i in 1:n_col_metric_matrix){
# add index
returned_list[[my_metric_names[i]]][["best_param_index"]] = indexes_best_params[i]
# add param value
returned_list[[my_metric_names[i]]][["best_param_value"]] = best_params[i]
# add all metrics relative to that row (best param index row)
returned_list[[my_metric_names[i]]][["metric_values"]] = my_metric_matrix[indexes_best_params[i],]
}
return(returned_list)
}
ridge_no_int_best_summary = CvMetricBest(my_param_values = lambda_vals,
my_metric_matrix = ridge_no_interaction_metrics[["metrics"]],
my_one_se_best = TRUE,
my_higher_more_complex = FALSE,
my_se_matrix = ridge_no_interaction_metrics[["se"]],
my_metric_names = METRICS_NAMES,
indexes_metric_max = 4) # f_score: higher better
CvMetricBest = function(my_param_values,
my_metric_matrix,
my_se_matrix = 0,
my_metric_names,
my_one_se_best = TRUE,
my_higher_more_complex = TRUE,
indexes_metric_max = 0){
# this code is sub-optimal, someday I'll change it
# compute standard deviations matrix lower and upper
se_lower = my_metric_matrix - my_se_matrix
se_upper = my_metric_matrix + my_se_matrix
# BEST PARAM VALUES section
n_col_metric_matrix = NCOL(my_metric_matrix)
best_params = rep(NA, n_col_metric_matrix)
names(best_params) = my_metric_names
# Check metrics min and max best
if(indexes_metric_max == 0){
indexes_best_params = apply(as.matrix(my_metric_matrix), 2, which.min)
}
if(indexes_metric_max > 0){
indexes_best_params = c(apply(as.matrix(my_metric_matrix[,-indexes_metric_max]), 2, which.min),
apply(as.matrix(my_metric_matrix[,indexes_metric_max]), 2, which.max))
}
if(my_one_se_best == TRUE){
# non efficient procedure, but we assume the parameter space is small
# find all indexes for which the best error is inside the 1se band
for(i in 1:length(indexes_best_params)){
# more readable code
temp_best_metric = my_metric_matrix[indexes_best_params[i], i]
# parameter indexes for which the metric is inside the 1se band of best param metric
temp_param_indexes = which(my_param_values %in% my_param_values[which(temp_best_metric > se_lower[,i] &
temp_best_metric < se_upper[,i])])
if(my_higher_more_complex == TRUE){
indexes_best_params[i]= temp_param_indexes[which.min(my_param_values[temp_param_indexes])]
}
if(my_higher_more_complex == FALSE){
indexes_best_params[i]= temp_param_indexes[which.max(my_param_values[temp_param_indexes])]
}
}
}
best_params = my_param_values[indexes_best_params]
# return indexes and best param values
returned_list = list()
# cycle over all metrics
for (i in 1:n_col_metric_matrix){
# add index
returned_list[[my_metric_names[i]]][["best_param_index"]] = indexes_best_params[i]
# add param value
returned_list[[my_metric_names[i]]][["best_param_value"]] = best_params[i]
# add all metrics relative to that row (best param index row)
returned_list[[my_metric_names[i]]][["metric_values"]] = my_metric_matrix[indexes_best_params[i],]
}
return(returned_list)
}
ridge_no_int_best_summary = CvMetricBest(my_param_values = lambda_vals,
my_metric_matrix = ridge_no_interaction_metrics[["metrics"]],
my_one_se_best = TRUE,
my_higher_more_complex = FALSE,
my_se_matrix = ridge_no_interaction_metrics[["se"]],
my_metric_names = METRICS_NAMES,
indexes_metric_max = 4) # f_score: higher better
o
PlotAndSave(function()(
PlotCvMetrics(my_param_values = log(lambda_vals),
my_metric_matrix = ridge_no_interaction_metrics[["metrics"]],
my_se_matrix = ridge_no_interaction_metrics[["se"]],
my_best_param_values =log(ExtractBestParams(ridge_no_int_best_summary)),
my_metric_names = METRICS_NAMES,
my_main = "Ridge no interaction CV metrics",
my_xlab = " log lambda")),
my_path_plot = paste(FIGURES_FOLDER_RELATIVE_PATH,
"ridge_no_int_metrics_plot.jpeg",
collapse = ""))
PlotAndSave(function()(
PlotCvMetrics(my_param_values = log(lambda_vals),
my_metric_matrix = ridge_no_interaction_metrics[["metrics"]],
my_se_matrix = ridge_no_interaction_metrics[["se"]],
my_best_param_values =log(ExtractBestParams(ridge_no_int_best_summary)),
my_metric_names = METRICS_NAMES,
my_main = "Ridge no interaction CV metrics",
my_xlab = " log lambda")),
my_path_plot = paste(FIGURES_FOLDER_RELATIVE_PATH,
"ridge_no_int_metrics_plot.jpeg",
collapse = ""))
PlotAndSave(function()(
PlotCvMetrics(my_param_values = log(lambda_vals),
my_metric_matrix = ridge_no_interaction_metrics[["metrics"]],
my_se_matrix = ridge_no_interaction_metrics[["se"]],
my_best_param_values =log(ExtractBestParams(ridge_no_int_best_summary)),
my_metric_names = METRICS_NAMES,
my_main = "Ridge no interaction CV metrics",
my_xlab = " log lambda")),
my_path_plot = paste(FIGURES_FOLDER_RELATIVE_PATH,
"ridge_no_int_metrics_plot.jpeg",
collapse = ""))
PlotAndSave(function()(
PlotCvMetrics(my_param_values = log(lambda_vals),
my_metric_matrix = ridge_no_interaction_metrics[["metrics"]],
my_se_matrix = ridge_no_interaction_metrics[["se"]],
my_best_param_values =log(ExtractBestParams(ridge_no_int_best_summary)),
my_metric_names = METRICS_NAMES,
my_main = "Ridge no interaction CV metrics",
my_xlab = " log lambda")),
my_path_plot = paste(FIGURES_FOLDER_RELATIVE_PATH,
"ridge_no_int_metrics_plot.jpeg",
collapse = ""))
PlotAndSave(function()(
PlotCvMetrics(my_param_values = log(lambda_vals),
my_metric_matrix = ridge_no_interaction_metrics[["metrics"]],
my_se_matrix = ridge_no_interaction_metrics[["se"]],
my_best_param_values =log(ExtractBestParams(ridge_no_int_best_summary)),
my_metric_names = METRICS_NAMES,
my_main = "Ridge no interaction CV metrics",
my_xlab = " log lambda")),
my_path_plot = paste(FIGURES_FOLDER_RELATIVE_PATH,
"ridge_no_int_metrics_plot.jpeg",
collapse = ""))
print("ridge_no_int_best_summary")
ridge_no_int_best_summary
ridge_no_interaction = glmnet(x = X_mm_no_interaction_sss,
y = sss$y,
alpha = 0,
lambda = ridge_no_int_best_summary[[METRIC_CHOSEN_NAME]][["best_param_value"]])
df_metrics = Add_Test_Metric(df_metrics,
"ridge_no_interaction",
USED.Metrics(predict(ridge_no_interaction, newx = X_mm_no_interaction_vvv) > MY_THRESHOLD,
vvv$y,
weights = MY_WEIGHTS_vvv))
df_metrics
df_metrics = Add_Test_Metric(df_metrics,
"sss threshold",
USED.Metrics(y.pred = rbinom(nrow(vvv), 1, MY_THRESHOLD),
y.test = vvv$y,
weights = MY_WEIGHTS_vvv))
df_metrics
# save the df_metrics as .Rdata
save(df_metrics, file = "df_metrics.Rdata")
file_name_lasso_no_interaction = paste(MODELS_FOLDER_RELATIVE_PATH,
"lasso_no_interaction",
".Rdata", collapse = "", sep = "")
save(lasso_no_interaction, file = file_name_lasso_no_interaction)
# save the df_metrics as .Rdata
save(df_metrics, file = "df_metrics.Rdata")
file_name_ridge_no_interaction = paste(MODELS_FOLDER_RELATIVE_PATH,
"ridge_no_interaction",
".Rdata", collapse = "", sep = "")
save(ridge_no_interaction, file = file_name_ridge_no_interaction)
rm(ridge_no_interaction)
gc()
# YES Interaction -----------
lambda_vals = glmnet(x = X_mm_yes_interaction_sss, y = sss$y,
alpha = 0, lambda.min.ratio = 1e-07)$lambda
source("cv_functions.R")
